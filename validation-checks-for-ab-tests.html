<!DOCTYPE html>
<html lang="en">
<head>
  <meta name="google-site-verification" content="14dvQcWyDWHBo8aM0kld8XzEa6KypAzCQDz1_KPus9E" />
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-1812620-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-1812620-2');
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
    styles: {
    ".MathJax .mo, .MathJax .mi": {color: "black ! important"}}
    },
    tex2jax: {
      inlineMath: [['$','$'], ['\\\\(','\\\\)']],
      displayMath: [['$$','$$'], ["\\[","\\]"]],
      processEscapes: true,
    }
    });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" type="text/css" href="/theme/css/style.min.css">
  <!--<link rel="stylesheet" type="text/css" href="/theme/css/pygments.min.css">-->
  <link rel="stylesheet" type="text/css" href="/theme/css/pygments/github.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/font-awesome.min.css">
  <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Bytepawn - Marton Trencseni Atom">

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />
<meta name="author" content="Marton Trencseni" />
<meta name="description" content="In an ealier post, I wrote about A/B testing conversion data with the Z-test. The Chi-squared test is a more general test for conversion data, because it can work with multiple conversion events and multiple funnels being tested (A/B/C/D/..)." />
<meta name="keywords" content="ab-testing">
<meta property="og:site_name" content="Bytepawn - Marton Trencseni"/>
<meta property="og:title" content="Validation checks for A/B tests"/>
<meta property="og:description" content="In an ealier post, I wrote about A/B testing conversion data with the Z-test. The Chi-squared test is a more general test for conversion data, because it can work with multiple conversion events and multiple funnels being tested (A/B/C/D/..)."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="/validation-checks-for-ab-tests.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2020-04-16 00:00:00+02:00"/>
<meta property="article:modified_time" content="2020-04-16 00:00:00+02:00"/>
<meta property="article:author" content="/author/marton-trencseni.html">
<meta property="article:section" content="Data"/>
<meta property="article:tag" content="ab-testing"/>
<meta property="og:image" content="/images/chi2.png"/>

  <title>Bytepawn - Marton Trencseni &ndash; Validation checks for A/B tests</title>
</head>
<body>
  <aside>
    <div>
      <a href="/">
        <img src="/theme/img/profile.png" alt="" title="">
      </a>
      <!--<h2><a href="">Bytepawn - Marton Trencseni</a></h2>-->
      <h2><a href="http://bytepawn.com">Bytepawn</a></h2>
      <p></p>
      <nav>
        <ul class="list">
          <li><a href="/">home</a></li>
          <li><a href="https://github.com/mtrencseni">github</a></li>
          <li><a href="https://www.linkedin.com/in/mtrencseni">linkedin</a></li>
          <li><a href="http://arxiv.org/find/all/1/au:+trencseni/0/1/0/all/0/1">arxiv</a></li>
        </ul>
      </nav>
      <ul class="social">
      </ul>
    </div>
  </aside>
  <main>

<article>
  <header>
    <h1 id="validation-checks-for-ab-tests">Validation checks for A/B tests</h1>
    <p>Marton Trencseni - Thu 16 April 2020 - <a href="/category/data.html">Data</a></p>
  </header>
  <div>
    <h2>Introduction</h2>
<p><em>"Anything that can go wrong will go wrong"</em>, according to <a href="https://en.wikipedia.org/wiki/Murphy%27s_law">Murphy’s law</a>. A/B testing is no different. Anybody who has run a lot of A/B tests, over several years, has seen multiple failure modes. Some errors I've seen (assuming “B” is the new experimental funnel in the A/B test):</p>
<ul>
<li>misconfigured test: we want to do a 20%-80% split, but we accidentally configure 80%-20% split instead</li>
<li>test left on: we conclude the test, and want to remove A or B from production, but accidentally leave the test on with the original traffic split</li>
<li>randomization bias: users are not assigned into A and B randomly</li>
<li>logging problem: no/less/faulty logs coming from B</li>
<li>buggy product: a software bug in B causes users to drop out</li>
</ul>
<p>Let’s look at how we can automatically catch some of these problems. Note that in all of the tests below, we are doing a two-tailed test, since we want to catch errors in either direction.</p>
<p><a href="https://github.com/mtrencseni/playground/blob/master/Validation%20checks%20for%20AB%20tests.ipynb">The code shown below is up on Github.</a></p>
<h2>Problem: misconfigured test, missing exposure logs</h2>
<p>This is the easiest to catch, assuming we have an independent validation system that is correctly configured. On the one hand, if this is the case, we can simply write code that checks whether the configured traffic splits match in production vs validation. However, this is often not possible, because eg. the production configuration is hardcoded into Python or Java source code files.</p>
<p>In this case, we can perform validation on the exposure logs. Exposure log just means a log entry which is generated when a user is assigned into the funnels A or B. We can do a check using the one-way $\chi^2$-squared test: if we expect an 80%-20% split between A and B (were 80-20 is typed a second time in the validation check), we can check how likely it is that the exposure log counts for A and B are coming from that distribution. If there is a misconfiguration, we will get a very low p-value, and can alert on it:</p>
<div class="highlight"><pre><span></span><span class="n">N</span><span class="o">=</span><span class="mi">10</span><span class="o">*</span><span class="mi">1000</span>
<span class="n">traffic_split</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]</span>
<span class="n">user_counts</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1987</span><span class="p">,</span> <span class="mi">8013</span><span class="p">]</span> <span class="c1"># bad</span>
<span class="c1">#user_counts = [8013, 1987] # good</span>
<span class="c1"># simulates a case where we accidentally switched A and B</span>
<span class="c1"># so the test would return a very low ~0 p value, indicating</span>
<span class="c1"># that it&#39;s very unlikely that the observed counts are coming from</span>
<span class="c1"># the indicated traffic_split</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">chisquare</span><span class="p">(</span><span class="n">user_counts</span><span class="p">,</span> <span class="n">f_exp</span><span class="o">=</span><span class="p">[</span><span class="n">N</span><span class="o">*</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">traffic_split</span><span class="p">])[</span><span class="mi">1</span><span class="p">]</span>
<span class="k">if</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="n">p_crit</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Low p value (</span><span class="si">%f</span><span class="s1">). Probably indicated badly configured test, or bad logs!&#39;</span> <span class="o">%</span> <span class="n">p</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Everything seems good.&#39;</span><span class="p">)</span>
</pre></div>


<p>For automation, I would use a very small critical p-value like 0.001 or 0.0001, since we’re not interested in statistical fluctuations, we want to catch misconfiguration, which will even at moderate sample sizes yield a very very small p value, close to 0.</p>
<p>Note that here we’re not doing a significance test on the outcome of the A/B test. We’re just making sure the split is what we think it is. In the example above, we assumed that out of 10,000 impressions, 1,987 were in the A funnel, and it’s configured to get 80% of the traffic. The $\chi^2$-squared test that then tells us this is an extremely unlikely outcome. Note that the above $\chi^2$-squared test can be run for experiments with more than 2 funnels.</p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="/tag/ab-testing.html">ab-testing</a>
    </p>
  </div>
</article>

    <footer>
      <p>&copy; Marton Trencseni </p>
<p>Built using <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a></p>    </footer>
  </main>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1812620-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1812620-2');
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "name": "Validation checks for A/B tests",
  "headline": "Validation checks for A/B tests",
  "datePublished": "2020-04-16 00:00:00+02:00",
  "dateModified": "2020-04-16 00:00:00+02:00",
  "author": {
    "@type": "Person",
    "name": "Marton Trencseni",
    "url": "/author/marton-trencseni.html"
  },
  "image": "{{ SITEURL }}/{{ THEME_STATIC_DIR }}/img/profile.png",
  "url": "/validation-checks-for-ab-tests.html",
  "description": "In an ealier post, I wrote about A/B testing conversion data with the Z-test. The Chi-squared test is a more general test for conversion data, because it can work with multiple conversion events and multiple funnels being tested (A/B/C/D/..)."
}
</script></body>
</html>