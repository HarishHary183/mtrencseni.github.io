<!DOCTYPE html>
<html lang="en">
<head>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
    styles: {
    ".MathJax .mo, .MathJax .mi": {color: "black ! important"}}
    },
    tex2jax: {
      inlineMath: [['$','$'], ['\\\\(','\\\\)']],
      displayMath: [['$$','$$'], ["\\[","\\]"]],
      processEscapes: true,
    }
    });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" type="text/css" href="/theme/css/style.min.css">
  <!--<link rel="stylesheet" type="text/css" href="/theme/css/pygments.min.css">-->
  <link rel="stylesheet" type="text/css" href="/theme/css/pygments/github.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/font-awesome.min.css">
  <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Bytepawn Atom">

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />
<meta name="author" content="Marton Trencseni" />
<meta name="description" content="I was grabbing a burger at Shake Shack, Mall of the Emirates in Dubai, when I noticed this notebook on the counter. The staff is using it to track food deliveries and each service (Carriage, Talabat, UberEats, Deliveroo) has its own column with the order numbers. Let's assume this is the only page for the day, and ask ourselves: given this data, what is the probability that UberEats is the most popular food delivery service?." />
<meta name="keywords" content="python, math">
<meta property="og:site_name" content="Bytepawn"/>
<meta property="og:title" content="Food deliveries, Bayes and Computational Statistics"/>
<meta property="og:description" content="I was grabbing a burger at Shake Shack, Mall of the Emirates in Dubai, when I noticed this notebook on the counter. The staff is using it to track food deliveries and each service (Carriage, Talabat, UberEats, Deliveroo) has its own column with the order numbers. Let's assume this is the only page for the day, and ask ourselves: given this data, what is the probability that UberEats is the most popular food delivery service?."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="/food-deliveries-bayes-and-computational-statistics.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2019-06-22 00:00:00+02:00"/>
<meta property="article:modified_time" content="2019-06-22 00:00:00+02:00"/>
<meta property="article:author" content="/author/marton-trencseni.html">
<meta property="article:section" content="Math"/>
<meta property="article:tag" content="python"/>
<meta property="article:tag" content="math"/>
<meta property="og:image" content="/images/shake-shack.jpg"/>

  <title>Bytepawn &ndash; Food deliveries, Bayes and Computational Statistics</title>
</head>
<body>
  <aside>
    <div>
      <a href="/">
        <img src="/theme/img/profile.png" alt="" title="">
      </a>
      <h1><a href=""></a></h1>
      <p></p>
      <nav>
        <ul class="list">
          <li><a href="/">home</a></li>
          <li><a href="https://github.com/mtrencseni">github</a></li>
          <li><a href="https://www.linkedin.com/in/mtrencseni">linkedin</a></li>
          <li><a href="http://arxiv.org/find/all/1/au:+trencseni/0/1/0/all/0/1">arxiv</a></li>
        </ul>
      </nav>
      <ul class="social">
      </ul>
    </div>
  </aside>
  <main>

<article>
  <header>
    <h1 id="food-deliveries-bayes-and-computational-statistics">Food deliveries, Bayes and Computational Statistics</h1>
    <p>Posted on Sat 22 June 2019 in <a href="/category/math.html">Math</a></p>
  </header>
  <div>
    <h2>Introduction</h2>
<p>I was grabbing a burger at <a href="https://www.shakeshack.com/location/dubai-moe/">Shake Shack</a>, <a href="http://www.malloftheemirates.com/">Mall of the Emirates</a> in Dubai, when I noticed this notebook on the counter. The staff is using it to track food deliveries, and each service <strong>(Carriage, Talabat, UberEats, Deliveroo)</strong> has its own column with the order numbers. Let's assume this is the only page for the day, and ask ourselves: <em>given this data, what is the probability that UberEats is the most popular food delivery service?</em>. <a href="https://github.com/mtrencseni/playground/blob/master/UberEats.ipynb">The ipython notebook is up on Github.</a></p>
<p><img src="/images/shake-shack.jpg" alt="Shake shack food deliveries" style="width: 400px;"/></p>
<p>This is good challenge to exercise our Bayesian reasoning. <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes theorem</a> states that $ P(A|B)P(B) = P(A,B) = P(B|A)P(A) $, where $ P(A|B ) $ is the conditional probability of A given B, and $ P(A, B) $ is the joint probability of A and B co-occuring. All we have to do is replace A with <strong>H for Hypothesis</strong> and B with <strong>D for Data</strong>, and we get our formula for attacking the challenge: $ P(H|D) = \frac { P(D|H)P(H) }{ P(D) } $. Here <strong>Hypothesis</strong> is that UberEats is the most popular service, and <strong>Data</strong> is the observed counts (2, 2, 16, 14) in the notebook.</p>
<h2>Simulation</h2>
<p>First, let's do a brute-force simulation. Our model is that there are 4 services, each service has an associated probability, the probabilities sum to 1. When a new orders arrives at Shake Shack, it is according to this model that the service is drawn. A single simulation run---given a model (so, 4 probabilities for each service, summing to 1)---consists of 2 + 2 + 16 + 14 = 34 draws, and the outcome is the distribution between the services, eg. (10, 10, 10, 4). In mathematics terms, this drawing is called a multinomial distribution, <code>numpy</code> has a <code>multinomial</code> function, so we will use that. So our outer loops looks something like:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">random</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">multinomial</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Carriage&#39;</span><span class="p">:</span>  <span class="mi">2</span><span class="p">,</span>
    <span class="s1">&#39;Talabat&#39;</span><span class="p">:</span>   <span class="mi">2</span><span class="p">,</span>
    <span class="s1">&#39;UberEats&#39;</span><span class="p">:</span>  <span class="mi">16</span><span class="p">,</span>
    <span class="s1">&#39;Deliveroo&#39;</span><span class="p">:</span> <span class="mi">12</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">n_models</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="k">def</span> <span class="nf">random_model</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span>
    <span class="n">s</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">p</span><span class="o">/</span><span class="n">s</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">ps</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">random_simulation</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">multinomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">ps</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_models</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">random_model</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
    <span class="c1"># call random_simulation(model, sum(data.values())) and count things</span>
</pre></div>


<p>Since this is a simulation, we had to introduce <code>n_model</code>, the number of random models we sample (the ensemble size). Now we just have to implement the $ P(H|D) $ formula. This is simple. $ P(D|H) $ is the fraction of <code>random_simulation</code> cases that match the data, when the model matches the hypotehesis (see next sentence). $ P(H) $ is the fraction of models (!) that match the hypothesis of UberEats being the most popular, ie. that probability being the highest. $ P(D) $ is the total number of cases when <code>random_simulation</code> matches the data. First, some helper functions:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">same_as_data</span><span class="p">(</span><span class="n">outcome</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">all</span><span class="p">([</span><span class="n">i</span> <span class="o">==</span> <span class="n">j</span> <span class="k">for</span>  <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">outcome</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()))])</span>

<span class="k">def</span> <span class="nf">model_satisfies_hypothesis</span><span class="p">(</span><span class="n">ps</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span> <span class="o">==</span> <span class="n">ps</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="c1"># UberEats</span>
</pre></div>


<p>We have to introduce another parameter, the number of trial runs per model, which we'll call <code>n_simulations</code>. The simulation is now (note that this is actually two loops, the list expression for <code>hits</code> is a loop):</p>
<div class="highlight"><pre><span></span><span class="n">n_models</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_simulations</span> <span class="o">=</span> <span class="mi">1000</span><span class="o">*</span><span class="mi">1000</span>

<span class="n">hits_total</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">hits_hypothesis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">num_model_satisfies_hypothesis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_models</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">random_model</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
    <span class="n">hits</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
        <span class="p">[</span><span class="n">same_as_data</span><span class="p">(</span><span class="n">random_simulation</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">())))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_simulations</span><span class="p">)]</span>
    <span class="p">)</span>
    <span class="n">hits_total</span> <span class="o">+=</span> <span class="n">hits</span>
    <span class="k">if</span> <span class="n">model_satisfies_hypothesis</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
        <span class="n">hits_hypothesis</span> <span class="o">+=</span> <span class="n">hits</span>
        <span class="n">num_model_satisfies_hypothesis</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>


<p>In terms of these variables:</p>
<div class="highlight"><pre><span></span><span class="n">p_data_given_hypothesis</span> <span class="o">=</span> <span class="n">hits_hypothesis</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_model_satisfies_hypothesis</span> <span class="o">*</span> <span class="n">n_simulations</span><span class="p">)</span>
<span class="n">p_hypothesis</span> <span class="o">=</span> <span class="n">num_model_satisfies_hypothesis</span> <span class="o">/</span> <span class="n">n_models</span>
<span class="n">p_data</span> <span class="o">=</span> <span class="n">hits_total</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_models</span> <span class="o">*</span> <span class="n">n_simulations</span><span class="p">)</span>
<span class="c1"># p_hypothesis_given_data = p_data_given_hypothesis * p_hypothesis / p_data</span>
<span class="c1"># but, for better numerics, the above simplifies to:</span>
<span class="n">p_hypothesis_given_data</span> <span class="o">=</span> <span class="n">hits_hypothesis</span><span class="o">/</span><span class="n">hits_total</span>
</pre></div>


<p>That's it! We just have to run this simulation, and it will tell us our desired probability. Unfortunately, this is actually a lot of <code>random()</code>, calls. On my Macbook, this takes a long time to run. So I modified it a bit, updated and displayed the estimate <code>hits_hypothesis/hits_total</code> as the simulation was running. This is what it looks like:</p>
<p><img src="/images/food-bayes-simu.png" alt="Food delivereis simulation" style="width: 600px;"/></p>
<p>Obviously it takes a long time for the simulation to converge. In fact, the <code>p_est</code> shown in the screenshot above is not correct, the simulation has not yet converged. The reason is that the simulation is sparse. In most cases, there are no hits, so we waste a lot of cycles not updating our estimate <code>hits_hypothesis/hits_total</code>.</p>
<h2>Monte Carlo integration</h2>
<p>The above code is a good start, but it's terribly inefficient. Actually, there's no reason to brute-force the simulation itself, since there is an <a href="https://en.wikipedia.org/wiki/Multinomial_distribution#Probability_mass_function">explicit formula for the multinomial probability</a> of drawing $ k_i $ given $ p_i $ probabilities. The package <code>scipy</code> implements it, it's also called <code>multinomial</code> (like the <code>numpy</code> one), but this is the explicit probability mass function, not a random draw. Actually all we have to do is replace one line, the <code>hits</code> calculation, to compute the fractional probability of observing the data. It changes the meaning of the variables (the <code>hits</code> variables are no longer integers counts, instead they're summed fractions), but the ratios are the same. So the simulation becomes:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">random</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multinomial</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Carriage&#39;</span><span class="p">:</span>  <span class="mi">2</span><span class="p">,</span>
    <span class="s1">&#39;Talabat&#39;</span><span class="p">:</span>   <span class="mi">2</span><span class="p">,</span>
    <span class="s1">&#39;UberEats&#39;</span><span class="p">:</span>  <span class="mi">16</span><span class="p">,</span>
    <span class="s1">&#39;Deliveroo&#39;</span><span class="p">:</span> <span class="mi">12</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">n_models</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span><span class="mi">1000</span>

<span class="k">def</span> <span class="nf">random_model</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span>
    <span class="n">s</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">p</span><span class="o">/</span><span class="n">s</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">ps</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">same_as_data</span><span class="p">(</span><span class="n">outcome</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">all</span><span class="p">([</span><span class="n">i</span> <span class="o">==</span> <span class="n">j</span> <span class="k">for</span>  <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">outcome</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()))])</span>

<span class="k">def</span> <span class="nf">model_satisfies_hypothesis</span><span class="p">(</span><span class="n">ps</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span> <span class="o">==</span> <span class="n">ps</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="c1"># UberEats</span>

<span class="n">hits_total</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">hits_hypothesis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">num_model_satisfies_hypothesis</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_models</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">random_model</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
    <span class="n">hits</span> <span class="o">=</span> <span class="n">multinomial</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span> <span class="c1"># &lt;-- this changed</span>
    <span class="n">hits_total</span> <span class="o">+=</span> <span class="n">hits</span>
    <span class="k">if</span> <span class="n">model_satisfies_hypothesis</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
        <span class="n">hits_hypothesis</span> <span class="o">+=</span> <span class="n">hits</span>
        <span class="n">num_model_satisfies_hypothesis</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">p_hypothesis_given_data</span> <span class="o">=</span> <span class="n">hits_hypothesis</span><span class="o">/</span><span class="n">hits_total</span>
<span class="k">print</span><span class="p">(</span><span class="n">p_hypothesis_given_data</span><span class="p">)</span>
</pre></div>


<p>Note that we now no longer need the variable <code>n_simulations</code>. This is now lighting fast, converges in a few seconds, and quickly tells us that the probability we're looking for is 72%. <strong>Given what I saw on the notebook, the probability that UberEats is their most popular delivery service is ~72%.</strong> Given this code, it's easy to check another one. What's the probability that Deliveroo is the most popular? Just change <code>model_satisfies_hypothesis</code>, run it again, and it's ~28%. The other two have almost zero chances of actually being the most popular.</p>
<p><em>Technical note: in this whole discussion I'm assuming a uniform prior, ie. I have no prior bias towards believing one service being more popular than the rest.</em></p>
<p>Before moving on, here's a screenshot of this version, but before it converges. It shows the initial oscillations, which is what we were observing with the brute-force simulations (note that it eventually converges to 0.72):</p>
<p><img src="/images/food-bayes-simu2.png" alt="Food delivereis simulation" style="width: 600px;"/></p>
<h2>Integrals</h2>
<p>In case you remember college calculus, what we're doing above is a <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo (MC) integration</a> of.</p>
<p>hello $ \frac { \int <em _sum="\sum" p_i>{\sum p_i = 1 \wedge p_3 = max(p_i)} P(x_i=k_i) dp_i } { \int </em> P(x_i=k_i) dp_i } $ world</p>
<p>where $ P(x_i = k_i) = \frac {N!}{x_1! ... x_s!} p_1^{x_1} ... p_s^{x_s} $ is the multinomial probability mass function evaluated at $ k_i = (2, 2, 16, 14), i = 1.. 4, N = \sum k_i = 34, s = 4$. hello $ \frac { \int <em _sum="\sum" p_i>{\sum p_i = 1, p_3 = max(p_i)} P(x_i=k_i) dp_i } { \int </em> P(x_i=k_i) dp_i } $ world</p>
<p>It's called Monte Carlo because instead of computing the integral explicitly, we're taking random samples in p-space and using that to estimate. The $ P() $ function above can be integrated, it's just a polynomial, and the whole integrals can be explicitly calculated with pen and paper (both nominator and denominator constrains are a hyperplane in 4D space, with the nominator being more tricky because of the $ max() $ constraint). I will let the reader do this as homework :)</p>
<p>If you're having trouble understanding this post, check out the free book <a href="https://greenteapress.com/wp/think-bayes/">Think Bayes</a>.</p>
<p><img src="/images/thinkbayes.png" alt="Think Bayes book" style="width: 300px;"/></p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="/tag/python.html">python</a>
      <a href="/tag/math.html">math</a>
    </p>
  </div>
</article>

    <footer>
      <p>&copy; Marton Trencseni </p>
<p>Built using <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a></p>    </footer>
  </main>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "name": "Food deliveries, Bayes and Computational Statistics",
  "headline": "Food deliveries, Bayes and Computational Statistics",
  "datePublished": "2019-06-22 00:00:00+02:00",
  "dateModified": "2019-06-22 00:00:00+02:00",
  "author": {
    "@type": "Person",
    "name": "Marton Trencseni",
    "url": "/author/marton-trencseni.html"
  },
  "image": "{{ SITEURL }}/{{ THEME_STATIC_DIR }}/img/profile.png",
  "url": "/food-deliveries-bayes-and-computational-statistics.html",
  "description": "I was grabbing a burger at Shake Shack, Mall of the Emirates in Dubai, when I noticed this notebook on the counter. The staff is using it to track food deliveries and each service (Carriage, Talabat, UberEats, Deliveroo) has its own column with the order numbers. Let's assume this is the only page for the day, and ask ourselves: given this data, what is the probability that UberEats is the most popular food delivery service?."
}
</script></body>
</html>