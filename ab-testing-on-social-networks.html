<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-1812620-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-1812620-2');
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
    styles: {
    ".MathJax .mo, .MathJax .mi": {color: "black ! important"}}
    },
    tex2jax: {
      inlineMath: [['$','$'], ['\\\\(','\\\\)']],
      displayMath: [['$$','$$'], ["\\[","\\]"]],
      processEscapes: true,
    }
    });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" type="text/css" href="/theme/css/style.min.css">
  <!--<link rel="stylesheet" type="text/css" href="/theme/css/pygments.min.css">-->
  <link rel="stylesheet" type="text/css" href="/theme/css/pygments/github.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/font-awesome.min.css">
  <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Bytepawn Atom">

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />
<meta name="author" content="Marton Trencseni" />
<meta name="description" content="I use Monte Carlo simulations to show that experimentation on social networks is a beatiful statistical problem with unexpected nuances due to network effects." />
<meta name="keywords" content="ab-testing">
<meta property="og:site_name" content="Bytepawn"/>
<meta property="og:title" content="A/B testing on social networks"/>
<meta property="og:description" content="I use Monte Carlo simulations to show that experimentation on social networks is a beatiful statistical problem with unexpected nuances due to network effects."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="/ab-testing-on-social-networks.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2020-03-09 00:00:00+01:00"/>
<meta property="article:modified_time" content="2020-03-09 00:00:00+01:00"/>
<meta property="article:author" content="/author/marton-trencseni.html">
<meta property="article:section" content="Data"/>
<meta property="article:tag" content="ab-testing"/>
<meta property="og:image" content="/images/strogatz2.png"/>

  <title>Bytepawn &ndash; A/B testing on social networks</title>
</head>
<body>
  <aside>
    <div>
      <a href="/">
        <img src="/theme/img/profile.png" alt="" title="">
      </a>
      <h1><a href=""></a></h1>
      <p></p>
      <nav>
        <ul class="list">
          <li><a href="/">home</a></li>
          <li><a href="https://github.com/mtrencseni">github</a></li>
          <li><a href="https://www.linkedin.com/in/mtrencseni">linkedin</a></li>
          <li><a href="http://arxiv.org/find/all/1/au:+trencseni/0/1/0/all/0/1">arxiv</a></li>
        </ul>
      </nav>
      <ul class="social">
      </ul>
    </div>
  </aside>
  <main>

<article>
  <header>
    <h1 id="ab-testing-on-social-networks">A/B testing on social networks</h1>
    <p>Posted on Mon 09 March 2020 in <a href="/category/data.html">Data</a></p>
  </header>
  <div>
    <h2>Introduction</h2>
<p>In the <a href="http://bytepawn.com/tag/ab-testing.html">previous posts on A/B testing</a> we have implicitly assumed independece:</p>
<ul>
<li>if $A_1$ and $A_2$ are two units in the A bucket, the choices of $A_1$ and $A_2$ are independent of each other</li>
<li>the same across A and B</li>
</ul>
<p>This even went into the math, because the <a href="https://en.wikipedia.org/wiki/Central_limit_theorem">Central Limit Theorem</a> assumes that the random variables added are independent. But the point this post drives home is not going to be about the CLT.</p>
<p>Let’s take the case of post production. An experiment could test whether people are more likely to create a post if the UI element for posting is bigger and more prominent. If this product does not have a sharing/network component, it’s reasonable to make the above 2 independence assumptions. But on a social network the above assumptions do not hold. If the experiment boosts post production, this could lead to their friends seeing more posts in their feed, which in turn could lead to them posting more, which in turn... and so on.</p>
<p>Sticking to the post production example, we can model the effect if we split posting propensity into two parts:</p>
<ul>
<li>intrinsic: a random variable which describes how many posts daily a user on the network is likely to create</li>
<li>network: users are more likely to create posts if their friends create more posts</li>
</ul>
<p>Let’s assume that group A gets the UI element and it actually boosts their instrinsic post production. Because of the network effect, we will:</p>
<ul>
<li>measure an increased boost for A (vs just the intrinsic effect), because of A-A “self” interaction (network effect)</li>
<li>measure an increased boost for B (vs no effect), because of A-B interaction (spillover effect)</li>
<li>since B is also boosted, A-B interaction also boosts A; everything is boosted, to a different degree</li>
</ul>
<p>Additionally:</p>
<ul>
<li>the effect we measure in A (intrinsic effect plus network effect) will be less than what we get if we release A to 100%, since then the whole network will reinforce</li>
<li>the network effect depends on the social network: more connections means more reinforcement</li>
</ul>
<p><a href="https://github.com/mtrencseni/playground/blob/master/AB%20testing%20on%20social%20networks.ipynb">The code shown below is up on Github.</a></p>
<h2>Watts–Strogatz random graphs</h2>
<p>Let’s run some Monte Carlo simulations to see this in action. We will use a random <a href="https://en.wikipedia.org/wiki/Watts%E2%80%93Strogatz_model">Watts–Strogatz model</a> for the social network, and use the <a href="https://networkx.github.io/">networkx</a> library to generate it for us. The Watts-Strogatz model creates a graph with $n$ nodes, arranged in a ring, with each node connected to the next $k$ nodes in the ring; this initial setup is clustered, and has a high diameter. Then, with probability $p$, each edge is re-connected to a random node on the ring, this causes the diameter of the graph to drop and produces a “small-world graph”, where every node is reachable from every other node in a low number of hops.</p>
<p>Some examples of Watts–Strogatz graphs:</p>
<div class="highlight"><pre><span></span><span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">connected_watts_strogatz_graph</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">))</span>
</pre></div>


<p><img src="/images/strogatz1.png" alt="Watts–Strogatz random graph" style="width: 400px;"/></p>
<div class="highlight"><pre><span></span><span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">connected_watts_strogatz_graph</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>
</pre></div>


<p><img src="/images/strogatz2.png" alt="Watts–Strogatz random graph" style="width: 400px;"/></p>
<div class="highlight"><pre><span></span><span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">connected_watts_strogatz_graph</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>
</pre></div>


<p><img src="/images/strogatz3.png" alt="Watts–Strogatz random graph" style="width: 400px;"/></p>
<p>For initial exploration, I will use a small graph:</p>
<div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">connected_watts_strogatz_graph</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">to_directed</span><span class="p">()</span>
</pre></div>


<h2>Post production model</h2>
<p>For post production, let’s follow the simple model given above, with two parts:</p>
<ul>
<li>intrinsic post production</li>
<li>network effects: seeing my friend's post causes me to proportionally post more</li>
</ul>
<p>In code, we will run the simulation day-to-day, ie. posts from day T will trigger people to post more or day T+1. In this toy model, we will allow non-numeric post production, so people can write eg. 0.1134 posts a day:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">step_posts</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">yesterday_posts</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">intrinsic</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">network_effect</span><span class="o">=</span><span class="mf">0.03</span><span class="p">):</span>
    <span class="n">today_posts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="c1"># baseline</span>
    <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="n">today_posts</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="n">intrinsic</span> <span class="o">*</span> <span class="n">random</span><span class="p">()</span>
    <span class="c1"># network effect</span>
    <span class="k">if</span> <span class="n">yesterday_posts</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">:</span>
            <span class="n">today_posts</span><span class="p">[</span><span class="n">v2</span><span class="p">]</span> <span class="o">+=</span> <span class="n">yesterday_posts</span><span class="p">[</span><span class="n">v1</span><span class="p">]</span> <span class="o">*</span> <span class="n">network_effect</span> <span class="o">*</span> <span class="n">random</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">today_posts</span>
</pre></div>


<p>We can drive it like:</p>
<div class="highlight"><pre><span></span><span class="n">T</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">posts_series</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
    <span class="n">posts</span> <span class="o">=</span> <span class="n">step_posts</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="bp">None</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">posts_series</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">posts_series</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">posts_series</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">posts</span><span class="p">)</span>
</pre></div>


<p>It will take a few days for the network to reach equilibrium:</p>
<div class="highlight"><pre><span></span><span class="n">avg_posts</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">posts</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span> <span class="k">for</span> <span class="n">posts</span> <span class="ow">in</span> <span class="n">posts_series</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;t&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;avg posts&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">avg_posts</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p>Prints something like:</p>
<p><img src="/images/sn1.png" alt="Post production" style="width: 600px;"/></p>
<p>We see that with the parameters used, it converges to 0.5 posts / day on average across the network after about $T_c=20$ steps:</p>
<div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">avg_posts</span><span class="p">[</span><span class="mi">20</span><span class="p">:])</span>
</pre></div>


<p>Prints somethings like:</p>
<div class="highlight"><pre><span></span><span class="mf">0.5040494951777046</span>
</pre></div>


<p>It’s easy to see why. On the first day, each person produces <code>intrinsic * random()</code> posts, where <code>intrinsic = 0.25</code> and <code>random()</code> is a $U(0, 1)$ uniform random variable, so on average it’s 0.5. So this part is on average $c=0.125$. Then, starting the second day, each person produces $c$ on average, plus for each friend, <code>yesterday_posts[v1] * network_effect * random()</code> additional posts, where <code>network_effect = 0.03</code>, and from the graph each person has 50 friends. So overall this is on average $c * k$, with $k = 50 * 0.03 * 0.5 = 0.75$. Once equilibrium is reached, the following holds: $c_{next} = c + c_{next} * k$. Solving this, $c_{next} = 0.5$.</p>
<p>Note that the intrinsic part averages 0.125, and the network effect adds on another 0.375. <strong>In this toy model, 3 out of 4 posts is the result of network effects!</strong> This is a good qualitative indication why network effects are so important for engagement.</p>
<p>We can also see that by making the network effect too strong, either by having too many friends or setting <code>network_effect</code> too high, we get exponential growth (in this case, the $c_{next}$ equation yields a nonsensical negative solution). For example, if we double the friend count to 100 (but keep everything else the same):</p>
<p><img src="/images/sn2.png" alt="Post production" style="width: 600px;"/></p>
<h2>Experiments</h2>
<p>Let’s do an experiment and see what happens. For this, let's:</p>
<ul>
<li>use a bigger graph, with $n=100,000$ nodes, but keep $k=50$</li>
<li>pick out $N=1,000$ people randomly ("population A"), and boost their intrinsic post production by 5%</li>
</ul>
<p>Code:</p>
<div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">connected_watts_strogatz_graph</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">100</span><span class="o">*</span><span class="mi">1000</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">to_directed</span><span class="p">()</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">population_A</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>
<span class="n">effect_size</span> <span class="o">=</span> <span class="mf">0.05</span>

<span class="k">def</span> <span class="nf">step_posts</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">yesterday_posts</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">intrinsic</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">network_effect</span><span class="o">=</span><span class="mf">0.03</span><span class="p">):</span>
    <span class="n">today_posts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="c1"># baseline</span>
    <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">population_A</span><span class="p">:</span>
            <span class="c1"># experiment</span>
            <span class="n">today_posts</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="n">intrinsic</span> <span class="o">*</span> <span class="n">random</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">effect_size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">today_posts</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="n">intrinsic</span> <span class="o">*</span> <span class="n">random</span><span class="p">()</span>
    <span class="c1"># network effect</span>
    <span class="k">if</span> <span class="n">yesterday_posts</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">:</span>
            <span class="n">today_posts</span><span class="p">[</span><span class="n">v2</span><span class="p">]</span> <span class="o">+=</span> <span class="n">yesterday_posts</span><span class="p">[</span><span class="n">v1</span><span class="p">]</span> <span class="o">*</span> <span class="n">network_effect</span> <span class="o">*</span> <span class="n">random</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">today_posts</span>
</pre></div>


<p>Looking at the converged part of the timeline, this is what we get for (i) overall post production, (ii) just A, (iii) friends of A and (iv) rest:</p>
<p><img src="/images/sn3.png" alt="Post production" style="width: 600px;"/></p>
<p>Combining all the days, we can get better statistics:</p>
<div class="highlight"><pre><span></span><span class="n">base</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="k">def</span> <span class="nf">lift</span><span class="p">(</span><span class="n">a</span><span class="p">):</span> <span class="k">return</span> <span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="n">base</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;A lift: </span><span class="si">%.3f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">lift</span><span class="p">(</span><span class="n">avg_posts_A</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Friends of A lift: </span><span class="si">%.3f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">lift</span><span class="p">(</span><span class="n">avg_posts_A_friends</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Rest lift: </span><span class="si">%.3f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">lift</span><span class="p">(</span><span class="n">avg_posts_rest</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Overall lift: </span><span class="si">%.3f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">lift</span><span class="p">(</span><span class="n">avg_posts_all</span><span class="p">))</span>
</pre></div>


<p>So compared to the base of 0.5 (no experiment), we measure:</p>
<div class="highlight"><pre><span></span><span class="n">A</span> <span class="n">lift</span><span class="p">:</span>            <span class="mf">1.702</span><span class="o">%</span>
<span class="n">Friends</span> <span class="n">of</span> <span class="n">A</span> <span class="n">lift</span><span class="p">:</span> <span class="mf">0.605</span><span class="o">%</span>
<span class="n">Rest</span> <span class="n">lift</span><span class="p">:</span>         <span class="mf">0.411</span><span class="o">%</span>
<span class="n">Overall</span> <span class="n">lift</span><span class="p">:</span>      <span class="mf">0.501</span><span class="o">%</span>
</pre></div>


<p>These results are very interesting:</p>
<ul>
<li><strong>the network effect is dampened:</strong> we underestimate the true intrinsic effect (1.7% vs 5%), because A’s non-A friends don’t have the feature, so As don’t get the boost “back” through these edges</li>
<li><strong>spillover effect:</strong> we measure a lift due to the network effect for friends of A, and further down the network, depending on the distance from As</li>
<li>if we release this feature to the entire network, average post production would be $ (1 + 0.05) \times 0.25 \times 0.5 / (1 - 50 \times 0.5 \times 0.03) = 0.525$, or a 5% lift compared to the base of 0.5, as expected</li>
<li>the overall lift is higher than the “rest” because A is pulling it up</li>
<li>the last 2 lifts can be made arbitrarily small by increasing the overall size $n$ of the network while keeping the experimental group size $N$ fixed</li>
</ul>
<p>The problem of the network effect dampening is a function of the relative strength of the network effect. In this simulation, we set the parameters so that the network effect is very strong, and boosts average post production from 0.125 to 0.5, by 4x! If the network effect were weaker, the experimental dampening would also be weaker, and the same for the spillover effect.</p>
<p>We can see this in action by repeating the experiment with <code>network_effect = 0.01</code>, so a 3x weaker network effect. In this case, the base value works out to 0.1666 (no experiment), and compared to this base, we measure (with +5% post production for the $N=1000$ population A):</p>
<div class="highlight"><pre><span></span><span class="n">A</span> <span class="n">lift</span><span class="p">:</span>            <span class="mf">3.777</span><span class="o">%</span>
<span class="n">Friends</span> <span class="n">of</span> <span class="n">A</span> <span class="n">lift</span><span class="p">:</span> <span class="mf">0.070</span><span class="o">%</span>
<span class="n">Rest</span> <span class="n">lift</span><span class="p">:</span>         <span class="mf">0.032</span><span class="o">%</span>
<span class="n">Overall</span> <span class="n">lift</span><span class="p">:</span>      <span class="mf">0.085</span><span class="o">%</span>
</pre></div>


<p>This confirms the above: if the network effect is weaker, the measured lift in the experimental group is closer to the effect size because the network effect dampening is lower (3.77% vs 1.70%), while the spillover effect is lower (0.07% vs 0.60%). We can achieve the same effect of making the network effect smaller by decreasing the edge count of the graph, ie. we would get the same result by using a $k=50/3$ Watts–Strogatz graph instead of a $k=50$ one.</p>
<p>Another interesting experiment is if we pick out a highly clustered population for the experiment group A. We can achieve this by:</p>
<div class="highlight"><pre><span></span><span class="n">population_A</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">)[:</span><span class="n">N</span><span class="p">])</span> <span class="c1"># set(sample(g.nodes, N))</span>
</pre></div>


<p>For reference, the commented out above is the original, randomly sampled population. First, let’s make sure that this way of picking out $N=1,000$ is in fact more highly clustered than properly sampling. In the original setup, we expect each A to have on average N/n = 1% of neighbours that are also in A, whereas by picking out N subsequent nodes, since only $p=0.1$ portion of edges were re-arranged in the Watts-Strogatz process, we expect this ratio to be significantly higher:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ratio_AA_friendship</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">population_A</span><span class="p">):</span>
    <span class="n">num_AA_edges</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([(</span><span class="n">v1</span> <span class="ow">in</span> <span class="n">population_A</span> <span class="ow">and</span> <span class="n">v2</span> <span class="ow">in</span> <span class="n">population_A</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">])</span>
    <span class="n">num_A_edges</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([(</span><span class="n">v1</span> <span class="ow">in</span> <span class="n">population_A</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">num_AA_edges</span> <span class="o">/</span> <span class="n">num_A_edges</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%.2f</span><span class="s1">&#39;</span><span class="o">%</span> <span class="n">ratio_AA_friendship</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="nb">set</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">,</span> <span class="n">N</span><span class="p">))))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%.2f</span><span class="s1">&#39;</span><span class="o">%</span> <span class="n">ratio_AA_friendship</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="nb">set</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">)[:</span><span class="n">N</span><span class="p">])))</span>
</pre></div>


<p>Prints something like:</p>
<div class="highlight"><pre><span></span><span class="mf">0.01</span>
<span class="mf">0.89</span>
</pre></div>


<p>With proper random sampling, the ratio is indeed 1%, whereas in the highly clustered case 89% of A’s friends are also As. So in this setup, we expect the measured A lift to be much closer to the true lift of 5% (using the original <code>network_effect = 0.03</code>). Running the simulation with this clustered A population, we get:</p>
<div class="highlight"><pre><span></span><span class="n">A</span> <span class="n">lift</span><span class="p">:</span>            <span class="mf">4.307</span><span class="o">%</span>
<span class="n">Friends</span> <span class="n">of</span> <span class="n">A</span> <span class="n">lift</span><span class="p">:</span> <span class="mf">0.579</span><span class="o">%</span>
<span class="n">Rest</span> <span class="n">lift</span><span class="p">:</span>         <span class="mf">0.460</span><span class="o">%</span>
<span class="n">Overall</span> <span class="n">lift</span><span class="p">:</span>      <span class="mf">0.508</span><span class="o">%</span>
</pre></div>


<p>The result is as expected: the measured lift is much closer to the true lift than with a true random sampled A population (4.3% is much closer to 5% than 1.7% is). It’s interesting that the friends of A lift is not much different (0.58% vs 0.60%). If A is more clustered, the set of non-A friends will be smaller (because there’s less edges going to non-As), but each of them on average (at least in the high $n$ limit) still has the same number of A friends, so the A boost they get will be similar.</p>
<h2>Conclusion</h2>
<p>When there are no network effects, or they are weak, a regular A/B test with one of the tests discussed in <a href="http://bytepawn.com/tag/ab-testing.html">earlier posts</a> works fine. But if there are strong network effects, these have to be taken into account when estimating lift and p-values. In real life there are a lot more nuances to take into account, both related to the network effects and otherwise (eg. cannibalizing photo posts when testing video post lift).</p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="/tag/ab-testing.html">ab-testing</a>
    </p>
  </div>
</article>

    <footer>
      <p>&copy; Marton Trencseni </p>
<p>Built using <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a></p>    </footer>
  </main>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1812620-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1812620-2');
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "name": "A/B testing on social networks",
  "headline": "A/B testing on social networks",
  "datePublished": "2020-03-09 00:00:00+01:00",
  "dateModified": "2020-03-09 00:00:00+01:00",
  "author": {
    "@type": "Person",
    "name": "Marton Trencseni",
    "url": "/author/marton-trencseni.html"
  },
  "image": "{{ SITEURL }}/{{ THEME_STATIC_DIR }}/img/profile.png",
  "url": "/ab-testing-on-social-networks.html",
  "description": "I use Monte Carlo simulations to show that experimentation on social networks is a beatiful statistical problem with unexpected nuances due to network effects."
}
</script></body>
</html>