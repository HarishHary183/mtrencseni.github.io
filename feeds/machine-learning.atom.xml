<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Bytepawn - Machine Learning</title><link href="/" rel="alternate"></link><link href="/feeds/machine-learning.atom.xml" rel="self"></link><id>/</id><updated>2019-02-08T00:00:00+01:00</updated><entry><title>PyTorch Basics: Solving the Ax=b matrix equation with autograd</title><link href="/pytorch-basics-solving-the-axb-matrix-equation-with-autograd.html" rel="alternate"></link><published>2019-02-08T00:00:00+01:00</published><updated>2019-02-08T00:00:00+01:00</updated><author><name>Marton Trencseni</name></author><id>tag:None,2019-02-08:/pytorch-basics-solving-the-axb-matrix-equation-with-autograd.html</id><summary type="html">&lt;p&gt;I will show how to solve the standard Ax=b matrix equation with PyTorch. This is a good toy problem to show some guts of the framework without involving neural networks.&lt;br/&gt;&lt;br/&gt;&lt;img src="/images/computational-graph.PNG" alt="PyTorch computational graph" style="width: 300px;"/&gt;&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;PyTorch is my favorite deep learning framework. It’s a hacker’s framework, It’s easier to work with than Tensorflow, which was developed for Google’s internal use-cases and ways of working, which just doesn’t apply to use-cases that are several orders of magnitude smaller (less data, less features, less prediction volume, less people working on it). There are tons of &lt;a href="https://pytorch.org/tutorials/"&gt;great tutorials&lt;/a&gt; and &lt;a href="https://www.youtube.com/watch?v=_H3aw6wkCv0"&gt;talks&lt;/a&gt; that help people quickly get a deep neural network model up and running with PyTorch. &lt;a href="https://pytorch.org/docs/stable/torchvision/datasets.html"&gt;PyTorch comes with standard datasets (like MNIST)&lt;/a&gt; and &lt;a href="https://pytorch.org/docs/stable/torchvision/models.html"&gt;famous models (like Alexnet) out of the box&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What actually goes on under the hood in these examples? At its core libraries like PyTorch are essentially computing derivatives of functions, and backpropagating the gradients in a computational graph; this is called autograd. This can also be applied to solve problems that don’t explicitly involve a deep neural network.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/computational-graph.PNG" alt="PyTorch computational graph" style="width: 300px;"/&gt;&lt;/p&gt;
&lt;p&gt;I will show how to solve the standard &lt;strong&gt;Ax=b&lt;/strong&gt; matrix equation with PyTorch. This is a good toy problem to show some guts of the framework without involving neural networks.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/axb.PNG" alt="Ax=b" style="width: 400px;"/&gt;&lt;/p&gt;
&lt;p&gt;As a reminder, in the &lt;strong&gt;Ax=b&lt;/strong&gt; matrix equation, &lt;strong&gt;A&lt;/strong&gt; is a fixed matrix, &lt;strong&gt;b&lt;/strong&gt; is a fixed vector, and we’re looking for vector &lt;strong&gt;x&lt;/strong&gt; such that &lt;strong&gt;Ax&lt;/strong&gt; is just the vector &lt;strong&gt;b&lt;/strong&gt;. If &lt;strong&gt;A&lt;/strong&gt; is a 1x1 matrix, then this is just a scalar equation, and &lt;strong&gt;x=b/A&lt;/strong&gt;. Let’s write this as &lt;strong&gt;x=A&lt;sup&gt;-1&lt;/sup&gt; b&lt;/strong&gt;, and then this applies to the n x n matrix case as well: the exact solution is to compute the inverse of &lt;strong&gt;A&lt;/strong&gt;, and multiply it by &lt;strong&gt;b&lt;/strong&gt;. (Note: the  technical conditions for a solution is &lt;strong&gt;detA != 0&lt;/strong&gt;, I'll ignore this since I'll be using random matrices). Let’s say the solution is x=x_s.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: using gradient descent to estimate the solution would be incredibly stupid in real life, as the solution can be computed quickly with matrix inversion. We're doing this to understand PyTorch on a toy problem.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;How can we use &lt;a href="https://pytorch.org/docs/stable/autograd.html"&gt;PyTorch and autograd&lt;/a&gt; to solve it? We can use it to approximate the solution: start with some random &lt;strong&gt;x_0&lt;/strong&gt;, compute the vector &lt;strong&gt;A x_0 - b&lt;/strong&gt;, take the norm &lt;strong&gt;L = || A x_0 - b ||&lt;/strong&gt;, and use a gradient descent to find a next, better &lt;strong&gt;x_1&lt;/strong&gt; vector so that it’s closer to the real solution &lt;strong&gt;x_s&lt;/strong&gt;. They key idea is that for &lt;strong&gt;x=x_s&lt;/strong&gt;, the norm is &lt;strong&gt;L = || A x_s - b || = 0&lt;/strong&gt;, so we essentially want to minimize that. This &lt;strong&gt;L&lt;/strong&gt; is called the loss function in such optimization problems.&lt;/p&gt;
&lt;p&gt;Let’s start with the standard L2 norm:&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/l2-definition.PNG" alt="L2 norm definition" style="width: 100px;"/&gt;&lt;/p&gt;
&lt;p&gt;This will result in a standarad parabolic loss function, where we will converge on the minimum.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/parabola2d.PNG" alt="L2 norm parabola" style="width: 300px;"/&gt;&lt;/p&gt;
&lt;h2&gt;Code&lt;/h2&gt;
&lt;p&gt;This is what the PyTorch code for setting up &lt;strong&gt;A, x&lt;/strong&gt; and &lt;strong&gt;b&lt;/strong&gt; looks like. We initialize &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;b&lt;/strong&gt; to random:&lt;/p&gt;
&lt;script src="https://gist.github.com/mtrencseni/d0f65883f2be329cac1ec390869d02e0.js"&gt;&lt;/script&gt;

&lt;p&gt;We set &lt;code&gt;requires_grad&lt;/code&gt; is set to &lt;code&gt;False&lt;/code&gt; for &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;b&lt;/strong&gt;. These are constants in this scenario, their gradient is zero. &lt;strong&gt;x&lt;/strong&gt; is the variable which we will compute gradients for, so we set &lt;code&gt;requires_grad = True&lt;/code&gt;.&lt;/p&gt;
&lt;script src="https://gist.github.com/mtrencseni/a232e345680f17f0c00ce816036308f1.js"&gt;&lt;/script&gt;

&lt;p&gt;We then tell PyTorch to do a backward pass and compute the gradients:&lt;/p&gt;
&lt;script src="https://gist.github.com/mtrencseni/4583fdf66ea02a4d4756103c734074c5.js"&gt;&lt;/script&gt;

&lt;p&gt;At this point, PyTorch will have compute the gradient for &lt;strong&gt;x&lt;/strong&gt;, stored in &lt;code&gt;x.grad.data&lt;/code&gt;. What this means is “adjust &lt;strong&gt;x&lt;/strong&gt; in this direction, by this much, to decrease the loss function, given what &lt;strong&gt;x&lt;/strong&gt; is right now”. Now we just need to introduce a step size to control our speed of descent, and actually adjust &lt;strong&gt;x&lt;/strong&gt;:&lt;/p&gt;
&lt;script src="https://gist.github.com/mtrencseni/c1929a58684b2962c4008b24564b48a0.js"&gt;&lt;/script&gt;

&lt;p&gt;Almost done. We just need to set &lt;code&gt;step_size&lt;/code&gt;, put this in a for loop, and figure out when to stop it:&lt;/p&gt;
&lt;script src="https://gist.github.com/mtrencseni/3e1b3d47f55fdb5a54518312d298940a.js"&gt;&lt;/script&gt;

&lt;p&gt;Let’s stop it when the loss is smaller than &lt;code&gt;stop_loss&lt;/code&gt;, and put an upper bound on the number of iterations:&lt;/p&gt;
&lt;script src="https://gist.github.com/mtrencseni/d6be2e6b35f100be1a92e6726f5210c2.js"&gt;&lt;/script&gt;

&lt;p&gt;It’s a good exercise to play around with this. Set a specific &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;b&lt;/strong&gt;, print things out, try other dimensions, etc.&lt;/p&gt;
&lt;h2&gt;Discussion&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;How is this related to neural networks?&lt;/strong&gt;&lt;br/&gt;
Imagine &lt;strong&gt;A&lt;/strong&gt; as a bitmap image, and &lt;strong&gt;b&lt;/strong&gt; as some sort of multi-classification (probability) output, and &lt;strong&gt;x&lt;/strong&gt; are the weights. We’re trying to get the neural network to learn the classification, in this trivial example, where the training set size is 1. Note that in real machine learning scenarios, the loss function (potential surface) is in a higher dimensional space and has several minima; the goal is not to find the global optimum (untractable), just a good enough local one (gets the job done).&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/potential-surface.PNG" alt="Potential surface" style="width: 300px;"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How do we know what step_size should be? How do we know when to stop?&lt;/strong&gt;&lt;br/&gt;
In this case, because the loss function we’re optimizing is quadratic, we can get away with a fixed step_size, as the gradient will get smaller as we approach the optimum (the solution). In more complicated deep neural network scanarios (where the step size is called the learning rate), there are strategies on how to gradually decay the step size. In general, if the step size is too small, we waste a lot of time far away from the solution. If it’s too big, we jump around the optimum and may never converge. See also &lt;a href="https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1"&gt;Learning Rate Schedules and Adaptive Learning Rate Methods for Deep Learning&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/learning-rate.PNG" alt="Learning rate" style="width: 300px;"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What should the stopping condition be?&lt;/strong&gt;&lt;br/&gt;
In this toy example, the &lt;code&gt;step_size&lt;/code&gt; is set smaller than &lt;code&gt;stop_loss&lt;/code&gt;, so it can converge on the optimum below the accepted loss. If you would set the &lt;code&gt;stop_loss&lt;/code&gt; to be much smaller than the step size, you will see that it never stops, it will jump around the optimum (left side of above picture).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What exactly is the quantity &lt;code&gt;x.grad.data&lt;/code&gt;?&lt;/strong&gt;&lt;br/&gt;
It stored the gradient of the loss function we called backward() on, with respect to the variable, in this case &lt;strong&gt;x&lt;/strong&gt;. So in the dim=1 case it’s just &lt;strong&gt;dL/dx&lt;/strong&gt;. Note that since &lt;strong&gt;x&lt;/strong&gt; is the only independent variable here, the partial derivative is the total derivative. If we had multiple independent variables, we'd have to add the partial derivates to get the &lt;a href="https://en.wikipedia.org/wiki/Total_derivative"&gt;total derivative&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What if we use the L1 norm as the loss function?&lt;/strong&gt;&lt;br/&gt;
To use the L1 norm, set &lt;code&gt;p=1&lt;/code&gt; in the code. The L1 norm in &lt;code&gt;dim=1&lt;/code&gt; is the &lt;strong&gt;abs()&lt;/strong&gt; function, so it’s derivative is piecewise constant. In this case the slope is &lt;strong&gt;+- ||A||&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/l1-norm.PNG" alt="L1 norm" style="width: 300px;"/&gt;&lt;/p&gt;
&lt;p&gt;This is “less nice” than the L2 norm for this simple case, because the gradient doesn’t vanish as the solution approaches the optimum. The solution is more likely to overshoot the optimum and oscillate. In this case this toy example is not representative of machine learning: real-world training sets often contain outliers, and L1 is more robust against outliers than L2.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What happens if we run this on the GPU vs CPU?&lt;/strong&gt;&lt;br/&gt;
To turn on the GPU, put this line at the top:&lt;/p&gt;
&lt;script src="https://gist.github.com/mtrencseni/ae8c2b405025c21a63c6562d8dc7dcff.js"&gt;&lt;/script&gt;

&lt;p&gt;On my computer, this is significantly slower on the GPU than the CPU, because copying such a small problem to the GPU creates a time overhead which is not worth it. This toy example is too small to demonstrate how GPUs speed deep learning.&lt;/p&gt;</content><category term="pytorch"></category></entry><entry><title>Automating a Call Center with Machine Learning</title><link href="/automating-a-call-center-with-machine-learning.html" rel="alternate"></link><published>2019-01-27T00:00:00+01:00</published><updated>2019-01-27T00:00:00+01:00</updated><author><name>Marton Trencseni</name></author><id>tag:None,2019-01-27:/automating-a-call-center-with-machine-learning.html</id><summary type="html">&lt;p&gt;Over a period of 6 months, we rolled out a Machine Learning model to predict a customer’s delivery (latitude, longitude). During the recent holiday peak, this ML model handled most of Fetchr’s order scheduling.&lt;br/&gt;&lt;br/&gt;&lt;img src="/images/ml-share3.png" alt="Share of ML scheduled versus Call center scheduled deliveries" style="width: 400px;"/&gt;&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Impact&lt;/h2&gt;
&lt;p&gt;Over a period of 6 months, we rolled out a Machine Learning model to predict a customer’s delivery (latitude, longitude). During the recent holiday peak, this ML model handled most of Fetchr’s order scheduling.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/ml-share3.png" alt="Share of ML scheduled versus Call center scheduled deliveries" style="width: 800px;"/&gt;&lt;/p&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In Europe and the US, addresses is not something we think about a lot. My address in Hungary is, for example:&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;em&gt;1114 Budapest, Szabolcska Mihaly u. 7&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Here “u.” stands for “utca”, which means “street”. 1114 is my zip code in Hungary. Sometimes I’m lazy and I shorten it, like:&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;em&gt;1114 BP, Szabolcska 7&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In the US, it’s customary to write it out in a different order and “street” is dropped:&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;em&gt;7 Szabolcska Mihaly, Budapest, 1114&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If I open Google Maps (in an incognito window), I can enter either of the three, and it will point me to the precise (latitude, longitude) of my apartment, which happens to be (47.476117, 19.044950).&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/szabolcska7.png" alt="Szabolcska Mihaly u. 7" style="width: 650px;"/&gt;&lt;/p&gt;
&lt;p&gt;I can give either address string to a delivery company in Hungary, and they will find my apartment. Why does this work? In the US and Europe, the following all hold:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;zip codes exist and everybody uses them&lt;/li&gt;
&lt;li&gt;address formats are reasonably standardized&lt;/li&gt;
&lt;li&gt;most people know what their address is (“my zip code is 1114”)&lt;/li&gt;
&lt;li&gt;most people know how to write out their addresses&lt;/li&gt;
&lt;li&gt;companies like Google have a known database of addresses (and maps)&lt;/li&gt;
&lt;li&gt;companies like Google have an incentive to make services like Google Maps work&lt;/li&gt;
&lt;li&gt;web shops can enforce address formats, eg. can force the user to select from known zip codes, street names in those zip codes, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In many countries in the Middle East, some of the above do not hold. For example, in the United Arab Emirates (UAE), there are no zip codes. There are street names, but which street a building falls on is often ambiguous. Also, streets have many names, official and slang, english and arabic. Often, people don’t know their streets: for example, I live in a hotel in Dubai, and I don’t know which street the building is on (more than half of the population in Dubai are expats). Sometimes buildings have a street number, sometimes not; sometimes people know the number, sometimes not. Finally, there are large areas, even in Dubai, where Google Maps doesn't know street names or numbers:&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/no-street-names.png" alt="No street names" style="width: 650px;"/&gt;&lt;/p&gt;
&lt;p&gt;Many times people also don't give their street name as an address, instead they give an area name (which is itself ambiguous) and building name (“Princess Tower”) or a nearby point of interest (POI) like “near Burger King in Al Barsha, next to SZR” ("SZR" stands for "Sheikh Zayed Road", it's a 2x8 lane super-highway in Dubai). This is the situation in cities like Dubai or Riyadh; in remote areas, in the desert, resolving locations is even harder.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: Interestingly, a few years ago the UAE government created a system to identify buildings called Makani codes, which is a 10 digit number. Every building in the UAE has a Makani code, and every building must have a plaque showing the Makani code. Unfortunately, very few people know their building's Makani code; it’s not widely used (eg. I don’t know my building's Makani code).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/makani.jpg" alt="Makani numbers" style="width: 650px;"/&gt;&lt;/p&gt;
&lt;p&gt;Here are some UAE and KSA addresses Fetchr delivered to in the past (changed capitalization to improve readability:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Near to Safeer Mall, Khuzam&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Greece Cluster, Building Greece 05 Shop 04, International City, Dubai&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Near by Emirates NBD, Nad Al Sheba, Dubai&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Batha Near Al Rajhi Building near Al Electron Building&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;I work at Royal Green Golf &amp;amp; Country Club&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;My home is near by colors street for car decoration in Jeddah&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Villa, King Khalid street, Down Town&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Google Maps or Open Street Maps doesn’t help here!&lt;/p&gt;
&lt;p&gt;The trick to a successful delivery in this region is the phone number! Unlike in the US or Europe, where an address is enough, here the &lt;strong&gt;phone number is king&lt;/strong&gt;; no package is accepted without the customer’s phone number. For incomplete or ambigious addresses, delivery companies rely on calling the customer to figure out where to go: call the customer, and try to figure out where to send the package based on the conversation with the customer, and then the package is dispatched to that (latitude, longitude). This is called &lt;strong&gt;scheduling&lt;/strong&gt;, the goal here is to figure out the spacetime coordinates of the delivery: (latitude, longitude, day, time), but we’ll ignore the (day, time) here.&lt;/p&gt;
&lt;h2&gt;Modeling&lt;/h2&gt;
&lt;p&gt;The problem we took on: given the freetext (phone, address), can we predict (latitude, longitude), so we can avoid a call to the customer? We set up a dummy service for this and got our software engineers to pass in the (phone, country, city, address); if we can make a good prediction, we return the predicted (latitude, longitude), else we return &lt;code&gt;NO_PREDICTION&lt;/code&gt;, in which case everything happens as before, the customer gets a call. (This is actually an oversimplification, for example the customer can also self-schedule using our app or mweb.)&lt;/p&gt;
&lt;p&gt;The service in production is running a number of models. A model is a way to predict the (latitude, longitude). When the service receives a (phone ... address) request, it goes through the models in a fixed order. If a model returns the (latitude, longitude), the service returns it. If the model returns &lt;code&gt;NO_PREDICTION&lt;/code&gt;, it moves on to the next. The models which returns the best quality coordinates is the first in line, and so on.&lt;/p&gt;
&lt;p&gt;So what models do we actually use? We currently have a total of 5 models running in production. I will describe 2 at a high level below.&lt;/p&gt;
&lt;h2&gt;Repeats&lt;/h2&gt;
&lt;p&gt;When working on building dashboards to understand our delivery operations, we created a metric which shows the % of our customers who are repeat customers. Customers can be identified by their phone numbers, which are also passed in as free text, but normalizing this is easy. It turns out we have a lot of customers that we’re already delivered to! This is an obvious opportunity: if we’ve delivered to a customer before, and recorded the actual (latitude, longitude) of the delivery (the driver app automatically does this when the package is delivered), then we can look this up. This should work most of the time, because people don’t move that often. This is the basic idea of this model (details omitted on purpose).&lt;/p&gt;
&lt;p&gt;The repeat model is simple, but it works amazingly well. The delivery performance (out of 100 dispatches, how many deliveries are successful) of this model outperforms our call center, and is on par with customer self-scheduling (which is the best channel). Part of the reason is that repeat customers are a biased group.&lt;/p&gt;
&lt;h2&gt;Address matching&lt;/h2&gt;
&lt;p&gt;What about non-repeat customers? Can we know where to go just based on the address?&lt;/p&gt;
&lt;p&gt;Initially we tried a lot of things, too many to detail here. Broadly:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;instead of predicting the (latitude, longitude), use a more coarse grained geographic division of zones (eg. divide Dubai into a few 100 polygons), and try to predict the correct zone; here we tried various approaches:&lt;ul&gt;
&lt;li&gt;building a separate model for each zone&lt;/li&gt;
&lt;li&gt;building one city-level model with multiple activations, one per zone&lt;/li&gt;
&lt;li&gt;decision tree and other models on feature vectors constructed from bag-of-words models, TF-IDF, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;use raw OpenStreetMaps (OSM) data, extracting “sites”, and matching to that&lt;/li&gt;
&lt;li&gt;mixing-and-matching the above two&lt;/li&gt;
&lt;li&gt;various string tokenization and matching approaches&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After a lot of experimentation, I wasn’t satisfied with the overall performance of the models, and I didn't have enough confidence to put them into production. However, after weeks of working with the data, I realized that I can try something pretty simple “by hand”. I usually look at Dubai data, and I noticed a lot of addresses include the area name, which is pretty unambigious, for example “Jumeirah Village Circle” or “Jumeirah Village Triangle”.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/jvt.png" alt="JVT and JVC" style="width: 650px;"/&gt;&lt;/p&gt;
&lt;p&gt;I knew that these areas were served by the same driver, because I’ve been out with him several times to understand what happens on the ground. So if the service returns the middle of the area as a (latitude, longitude) for those addresses, it’ll get dispatched by the correct driver, a good enough first step. So I spent a day looking at Google Maps and OSM and simply wrote out a few hundred rules by hand, did some quick sanity checks to make sure past addresses which would match these were in the right location, and then wrote a simple model which essentially does substring checking. I then put it into production for a few orders / day. A few days later I evaluated the delivery performance, and saw that while it’s not excellent, it’s not that bad. (I later removed this manual model from production, the ML version is much better).&lt;/p&gt;
&lt;p&gt;So the question was, how do I make this better, and generalize it? I noticed this pattern while looking at the data, clearly there’s more patterns like this in the data, let’s get the machine to learn it. This is what we did: there’s a backend component, which looks at all our historic deliveries, and finds good rules, the production service then just uses these rules (details omitted on purpose). It's an interesting approach: a rule based engine in production, but the rules are coming out of an ML model; this makes it really easy to tune (see below) and add/remove exceptions.&lt;/p&gt;
&lt;h2&gt;Knobs to turn&lt;/h2&gt;
&lt;p&gt;A really nice property of our models is that they have knobs to turn. On the repeat model, we can accept better or worse address similarity when comparing to past addresses. On the address matching type models, we can accept more or less tightly packed historic coordinates when deciding which rule to run in production. This allows us to turn knobs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;run models in “tight” mode, where we schedule less orders (more prediction queries return &lt;code&gt;NO_PREDICTION&lt;/code&gt; and go to the call center), but the returned coordinates are very accurate and hence we get good delivery performance.&lt;/li&gt;
&lt;li&gt;run models in “wide” mode, where we schedule more orders (less orders return &lt;code&gt;NO_PREDICTION&lt;/code&gt; and go to the call center), but the returned coordinates are on average less accurate and hence we get lower delivery performance---but we pass less orders to the call center.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can use these knobs to make choices. For example, if other scheduling channels are not available, it makes sense to run the model as wide as possible; and there's a break-even point, where the model performs as well on average as the call center.&lt;/p&gt;
&lt;h2&gt;Winner take all&lt;/h2&gt;
&lt;p&gt;The delivery market has a “winner take all” dynamic: more order volume means higher density, means more laoded drivers, means more efficient drivers, means lower cost. This also applies to the ML models. The more deliveries a company has made, the more repeats it will have (eventually, it will cover the entire population of a country/city). The more deliveries a company has made, the better address rules it can extract from its data. More past deliveries lead to higher efficiency today.&lt;/p&gt;
&lt;h2&gt;Statistical improvements&lt;/h2&gt;
&lt;p&gt;There are a lot of ways to improve these models. The simplest one is based on counting. Using the address matching model as a use-case, we can simply count how many dispatches are coming from each rule (like the toy model example &lt;code&gt;“jumeirah village triangle” -&amp;gt; (latitude, longitude)&lt;/code&gt;), compute the delivery performance (=deliveries/dispatches) for each rule, and prune the badly performing ones. There’s an exploration-exploitation trade-off here, so we use an epsilon-greedy strategy. For more on this, see &lt;a href="https://en.wikipedia.org/wiki/Multi-armed_bandit"&gt;multi-armed bandits&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Metrics&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Good Machine Learning goes hand in hand with good Data Engineering and Analytics.&lt;/strong&gt; This project came out of building 100s of charts and metrics to understand and visualize Fetchr’s operations and business. For this project, the most relevant were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Repeat %&lt;/strong&gt;: what % of our daily dispatches are going to customer we’ve delivered to before; the higher, the easier it is to do a good job on predicting customer location and behaviour based on past data. Since Fetchr is very successful and operates at scale, we have a fair share of repeats.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scheduling accuracy&lt;/strong&gt;: scheduling accuracy is the % of deliveries where the scheduled coordinate and the delivery coordinate is within X meters. The challenge is, the delivery coordinate is unreliable: sometimes the drivers update the order status hours after the delivery event (eg. while having coffee), so the delivery coordinate is unreliable. The scheduled coordinate itself could also be incorrect. But when the two are close together, it’s very likely that they point to the correct location. Scheduling accuracy can also be benchmarked when back-testing models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Delivery performance&lt;/strong&gt;: Delivery performance is a daily metric, it’s the % of dispatches that are successfully delivered. Delivery performance is not something we can back-test when building models, it has to be measured in production, experimentally, eg. on a small 1% release. (Delivery performance is the One Metric That Matters for delivery companies, we live and die by it.)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scheduling channel splits, model splits&lt;/strong&gt;: also a daily metric, it shows what % of dispatches came from which scheduling channel (call center, ML, self-scheduling, etc.), and specifically for the ML channel, what % came from which model.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conversion:&lt;/strong&gt; of all orders passed to the ML model for coordinate prediction, what % do we return a coordinate (instead of &lt;code&gt;NO_PREDICTION&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="/images/ml-conversion3.png" alt="ML Conversion%" style="width: 650px;"/&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The delivery coordinate prediction service has been a great success at Fetchr. The version currently in production is relatively simple, easy to understand and tunable, and adding exceptions is easy. There are lots of improvement opportunities in the current models themselves, ordering of models based on features, and of course making more complex models. Our goal is to go further up and toward the right in (conversion, accuracy) space!&lt;/p&gt;</content><category term="fetchr"></category><category term="machine-learning"></category><category term="call-center"></category></entry></feed>