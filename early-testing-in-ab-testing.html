<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-1812620-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-1812620-2');
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
    styles: {
    ".MathJax .mo, .MathJax .mi": {color: "black ! important"}}
    },
    tex2jax: {
      inlineMath: [['$','$'], ['\\\\(','\\\\)']],
      displayMath: [['$$','$$'], ["\\[","\\]"]],
      processEscapes: true,
    }
    });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" type="text/css" href="/theme/css/style.min.css">
  <!--<link rel="stylesheet" type="text/css" href="/theme/css/pygments.min.css">-->
  <link rel="stylesheet" type="text/css" href="/theme/css/pygments/github.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/font-awesome.min.css">
  <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Bytepawn Atom">

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />
<meta name="author" content="Marton Trencseni" />
<meta name="description" content="." />
<meta name="keywords" content="ab-testing">
<meta property="og:site_name" content="Bytepawn"/>
<meta property="og:title" content="Early stopping in A/B testing"/>
<meta property="og:description" content="."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="/early-testing-in-ab-testing.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2020-03-05 00:00:00+01:00"/>
<meta property="article:modified_time" content="2020-03-05 00:00:00+01:00"/>
<meta property="article:author" content="/author/marton-trencseni.html">
<meta property="article:section" content="Data"/>
<meta property="article:tag" content="ab-testing"/>
<meta property="og:image" content="/images/early_stopping.png"/>

  <title>Bytepawn &ndash; Early stopping in A/B testing</title>
</head>
<body>
  <aside>
    <div>
      <a href="/">
        <img src="/theme/img/profile.png" alt="" title="">
      </a>
      <h1><a href=""></a></h1>
      <p></p>
      <nav>
        <ul class="list">
          <li><a href="/">home</a></li>
          <li><a href="https://github.com/mtrencseni">github</a></li>
          <li><a href="https://www.linkedin.com/in/mtrencseni">linkedin</a></li>
          <li><a href="http://arxiv.org/find/all/1/au:+trencseni/0/1/0/all/0/1">arxiv</a></li>
        </ul>
      </nav>
      <ul class="social">
      </ul>
    </div>
  </aside>
  <main>

<article>
  <header>
    <h1 id="early-testing-in-ab-testing">Early stopping in A/B testing</h1>
    <p>Posted on Thu 05 March 2020 in <a href="/category/data.html">Data</a></p>
  </header>
  <div>
    <h2>Introduction</h2>
<p>In the past posts we’ve been computing p values for various <a href="https://en.wikipedia.org/wiki/Frequentist_inference">frequentist</a> statistical tests that are useful for A/B testing. When we modeled the A/B test, we assumed the protocol is:</p>
<ol>
<li>decide what metric (eg. conversion, timespent, DAU) we will use to evaluate the test</li>
<li>dedice how many $N$ samples we will collect</li>
<li>decide what type of test (eg. t-test or $\chi^2$) we will use</li>
<li>decide $\alpha$ acceptable false positive rate (FPR)</li>
<li>collect $N$ samples</li>
<li>compute $p$ value, if $p &lt; \alpha$ reject the null hypothesis, else accept it</li>
</ol>
<h2>Early stopping</h2>
<p>What happens if the tester follows a different protocol, and because they’re curious/impatient, peaks at the data repeatedly to see if it’s “already significant”. So instead of steps 5-6 above, they:</p>
<ul>
<li>collect $N_1$ samples, run hypothesis test on $N’ := N_1$ samples, compute $p$ value, if $p &lt;= \alpha$ reject the null hypothesis and stop, else go on</li>
<li>collect $N_2$ more samples, run hypothesis test on $N’ = N + N_2$ samples, compute $p$ value, if $p &lt;= \alpha$ reject the null hypothesis and stop, else go on</li>
<li>collect $N_3$ more samples...</li>
<li>stop if $N’ &gt;= N$</li>
</ul>
<p>What happens if the tester follows this early stopping protocol? We can simulate this protocol:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">abtest_episode</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">prior_observations</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">observations</span> <span class="o">=</span> <span class="n">simulate_abtest</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">prior_observations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">observations</span> <span class="o">+=</span> <span class="n">prior_observations</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">chi2_contingency</span><span class="p">(</span><span class="n">observations</span><span class="p">,</span> <span class="n">correction</span><span class="o">=</span><span class="bp">False</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">observations</span><span class="p">,</span> <span class="n">p</span>

<span class="k">def</span> <span class="nf">early_stopping_simulation</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">num_simulations</span><span class="p">,</span> <span class="n">episodes</span><span class="p">,</span> <span class="n">alphas</span><span class="p">):</span>
    <span class="n">hits</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_simulations</span><span class="p">):</span>
        <span class="n">observations</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">episodes</span><span class="p">)):</span>
            <span class="n">observations</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">abtest_episode</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">episodes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">observations</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">p</span> <span class="o">&lt;=</span> <span class="n">alphas</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">hits</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">break</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">hits</span> <span class="o">/</span> <span class="n">num_simulations</span>
    <span class="k">return</span> <span class="n">p</span>
</pre></div>


<p>Let’s assume our A/B test is actually not working (no lift), so both A and B are the same:</p>
<div class="highlight"><pre><span></span><span class="n">funnels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[[</span><span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the first vector is the actual outcomes,</span>
    <span class="p">[[</span><span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the second is the traffic split</span>
<span class="p">]</span>
</pre></div>


<p>First, let’s check that we get what we expect in the simple case, without early stopping:</p>
<div class="highlight"><pre><span></span><span class="n">Ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3000</span><span class="p">]</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">]</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">early_stopping_simulation</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Ns</span><span class="p">,</span> <span class="n">alphas</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;False positive ratio: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">p</span><span class="p">)</span>
</pre></div>


<p>Prints something like:</p>
<div class="highlight"><pre><span></span><span class="bp">False</span> <span class="n">positive</span> <span class="n">ratio</span><span class="p">:</span> <span class="mf">0.057</span>
</pre></div>


<p>This is what we expect. If the null hypothesis is true (A and B are the same), we expect to get $\alpha$ false positives, that’s exactly what $\alpha$ controls. Let’s see what happens if we collect the same amount of total samples, but follow the early stopping protocol with 2 extra peaks:</p>
<div class="highlight"><pre><span></span><span class="n">Ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1000</span><span class="p">]</span> <span class="o">*</span> <span class="mi">3</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">]</span> <span class="o">*</span> <span class="mi">3</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">early_stopping_simulation</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Ns</span><span class="p">,</span> <span class="n">alphas</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;False positive ratio: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">p</span><span class="p">)</span>
</pre></div>


<p>Prints something like:</p>
<div class="highlight"><pre><span></span><span class="bp">False</span> <span class="n">positive</span> <span class="n">ratio</span><span class="p">:</span> <span class="mf">0.105</span>
</pre></div>


<p>This is the problem with early stopping! If we repeatedly perform the significance test at the same $\alpha$ level, the overall $alpha$ level will be higher. If we do this, we will on average have a higher false positive rate than we think; in this simulation, with 2 extra peeks, at equal $N$ intervals, the FPR roughly doubles!</p>
<h2>Intuition</h2>
<p>Why does the False Positive Rate go up in the case of early stopping? The best way to see this is to evaluate the p value a lot of times, and plot the results. The simulation code is straightforward:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">repeated_significances</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">episodes</span><span class="p">):</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">observations</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">episodes</span><span class="p">)):</span>
        <span class="n">observations</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">abtest_episode</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">episodes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">observations</span><span class="p">)</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">observations</span><span class="p">)</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">results</span>
</pre></div>


<p>Let’s evaluate at every 100 samples, 100 times (total $N=10,000$), and run it 3 times:</p>
<div class="highlight"><pre><span></span><span class="n">Ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>

<span class="n">results1</span> <span class="o">=</span> <span class="n">repeated_significances</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">Ns</span><span class="p">)</span>
<span class="n">results2</span> <span class="o">=</span> <span class="n">repeated_significances</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">Ns</span><span class="p">)</span>
<span class="n">results3</span> <span class="o">=</span> <span class="n">repeated_significances</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">Ns</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;sample size&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">results1</span><span class="p">],</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">results1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">results2</span><span class="p">],</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">results2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">results3</span><span class="p">],</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">results3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">results3</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.05</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">results3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Test 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Test 2&#39;</span><span class="p">,</span> <span class="s1">&#39;Test 3&#39;</span><span class="p">,</span> <span class="s1">&#39;p = 0.05&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p>The result is something like:</p>
<p><img src="/images/early_stopping.png" alt="Early stopping" style="width: 600px;"/></p>
<p>There is no “correct” p value to compute at any point, since we are collecting samples from random process. The guarantee of frequentist hypothesis testing (as discussed in the past posts), is that, if we evaluate the data at the end (at $N=10,000$ on the chart, at the end), if the null hypothesis is true, then on average  in $1-\alpha$ fraction of cases the p value will be bigger than $\alpha$, and we will make the correct decision to accept the null hypothesis (the correct decision). But there is no guarantee about the trajectory of the p value in between. The trajectory is by definition random, so if we repeatedly test against the $p=0.05$ line with an early stopping protocol, then we will reject the null hypothesis (the incorrect decision) more often. In the case above, for the green line, we would have done so at the beinning, and for the orange line, we could have done so several times; even though at the end, as it happens, these tests would all (correctly) accept the null hypothesis.</p>
<p>A more formulaic way of saying this is to realize that the probability P(p_{N} &lt; 0.05 | H_0) is not the same as P(p_{N1} &lt; 0.05 | H_0) + P(p_{N1+N2} &lt; 0.05 | H_0 \wedge p_{N1} &gt; 0.05)) + ...</p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="/tag/ab-testing.html">ab-testing</a>
    </p>
  </div>
</article>

    <footer>
      <p>&copy; Marton Trencseni </p>
<p>Built using <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a></p>    </footer>
  </main>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1812620-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1812620-2');
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "name": "Early stopping in A/B testing",
  "headline": "Early stopping in A/B testing",
  "datePublished": "2020-03-05 00:00:00+01:00",
  "dateModified": "2020-03-05 00:00:00+01:00",
  "author": {
    "@type": "Person",
    "name": "Marton Trencseni",
    "url": "/author/marton-trencseni.html"
  },
  "image": "{{ SITEURL }}/{{ THEME_STATIC_DIR }}/img/profile.png",
  "url": "/early-testing-in-ab-testing.html",
  "description": "."
}
</script></body>
</html>