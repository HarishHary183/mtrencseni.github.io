<!DOCTYPE html>
<html lang="en">
<head>
  <meta name="google-site-verification" content="14dvQcWyDWHBo8aM0kld8XzEa6KypAzCQDz1_KPus9E" />
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-1812620-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-1812620-2');
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
    styles: {
    ".MathJax .mo, .MathJax .mi": {color: "black ! important"}}
    },
    tex2jax: {
      inlineMath: [['$','$'], ['\\\\(','\\\\)']],
      displayMath: [['$$','$$'], ["\\[","\\]"]],
      processEscapes: true,
    }
    });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" type="text/css" href="/theme/css/style.min.css">
  <!--<link rel="stylesheet" type="text/css" href="/theme/css/pygments.min.css">-->
  <link rel="stylesheet" type="text/css" href="/theme/css/pygments/github.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/font-awesome.min.css">
  <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Bytepawn - Marton Trencseni Atom">

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />
<meta name="author" content="Marton Trencseni" />
<meta name="description" content="I compare probabilities from Bayesian A/B testing with Beta distributions to frequentist A/B tests using Monte Carlo simulations. Under a lot of circumstances, the bayesian probability of the action hypothesis being true and the frequentist p value are complementary." />
<meta name="keywords" content="bayesian, ab-test">
<meta property="og:site_name" content="Bytepawn - Marton Trencseni"/>
<meta property="og:title" content="Bayesian A/B conversion tests"/>
<meta property="og:description" content="I compare probabilities from Bayesian A/B testing with Beta distributions to frequentist A/B tests using Monte Carlo simulations. Under a lot of circumstances, the bayesian probability of the action hypothesis being true and the frequentist p value are complementary."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="/bayesian-ab-conversion-tests.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2020-03-31 00:00:00+02:00"/>
<meta property="article:modified_time" content="2020-03-31 00:00:00+02:00"/>
<meta property="article:author" content="/author/marton-trencseni.html">
<meta property="article:section" content="Data"/>
<meta property="article:tag" content="bayesian"/>
<meta property="article:tag" content="ab-test"/>
<meta property="og:image" content="/images/bayes4.png"/>

  <title>Bytepawn - Marton Trencseni &ndash; Bayesian A/B conversion tests</title>
</head>
<body>
  <aside>
    <div>
      <a href="/">
        <img src="/theme/img/profile.png" alt="" title="">
      </a>
      <!--<h2><a href="">Bytepawn - Marton Trencseni</a></h2>-->
      <h2><a href="http://bytepawn.com">Bytepawn</a></h2>
      <p></p>
      <nav>
        <ul class="list">
          <li><a href="/">home</a></li>
          <li><a href="https://github.com/mtrencseni">github</a></li>
          <li><a href="https://www.linkedin.com/in/mtrencseni">linkedin</a></li>
          <li><a href="http://arxiv.org/find/all/1/au:+trencseni/0/1/0/all/0/1">arxiv</a></li>
        </ul>
      </nav>
      <ul class="social">
      </ul>
    </div>
  </aside>
  <main>

<article>
  <header>
    <h1 id="bayesian-ab-conversion-tests">Bayesian A/B conversion tests</h1>
    <p>Marton Trencseni - Tue 31 March 2020 - <a href="/category/data.html">Data</a></p>
  </header>
  <div>
    <h2>Introduction</h2>
<p>The A/B tests I talked about before, such as the <a href="http://bytepawn.com/ab-testing-and-the-ztest.html#ab-testing-and-the-ztest">Z-test</a>, <a href="http://bytepawn.com/ab-testing-and-the-ttest.html#ab-testing-and-the-ttest">t-test</a>, <a href="http://bytepawn.com/ab-testing-and-the-chi-squared-test.html#ab-testing-and-the-chi-squared-test">$\chi^2$ test</a>, <a href="http://bytepawn.com/ab-testing-and-the-gtest.html#ab-testing-and-the-gtest">G-test</a> and <a href="http://bytepawn.com/ab-testing-and-fishers-exact-test.html#ab-testing-and-fishers-exact-test">Fisher’s exact test</a> are so-called <strong>frequentist</strong> hypothesis testing methodologies. In <a href="https://en.wikipedia.org/wiki/Frequentist_inference">frequentist inference</a>, we formulate a $H_0$ null hypothesis and an $H_1$ action hypothesis, run the experiment, and then calculate the $p_f$ value ($f$ for frequentist), which is the probability of the outcome of the experiment being at least as extreme as the actual outcome, assuming the null hypothesis $H_0$ is true. For one-tailed conversion tests, $H_0$ is <em>“B is converting worse or the same as A”</em> and $H_1$ is <em>“B is converting better than A”</em>. In the frequentist setting, if the $p_f$ value is lower than some threshold $\alpha$ (usually $\alpha=0.01$ or $\alpha=0.05$), then we reject the null hypothesis, and accept the action hypothesis.</p>
<p>At a high level, <a href="https://en.wikipedia.org/wiki/Bayesian_inference"><strong>bayesian</strong> inference</a> turns this on its head and computes the probability $p_b$ ($b$ for bayesian) that $H_1$ is true (and $H_0$ is false) given the outcome of the experiment. If this probability is high, we accept the action hypothesis.</p>
<blockquote>
<p>Bayesian inference is a method of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available.</p>
</blockquote>
<p>We expect that the two are related: if there is a big difference in conversion in favor of B versus A, relative to the sample size $N$, we expect to get a low frequentist $p_f$ value and a high $p_b$ bayesian probability. However, in terms of the math, the two are not complementary probabilities: $p_f + p_b \neq 1$. However, as I will show here, this relationship approximately holds when doing conversion 2x2 A/B testing with Beta distributions and flat priors: $p_f + p_b \simeq 1 $.</p>
<p><a href="https://github.com/mtrencseni/playground/blob/master/Bayesian%20AB%20testing.ipynb">The code shown below is up on Github.</a></p>
<h2>Conversion parameter estimation with the Beta distribution</h2>
<p>In Bayesian modeling, we pick a distribution to model the $\mu$ conversion probability for each funnel A and B. In other words, we say <em>“I don’t know what the conversion of A is, but based on the experimental outcome, $P_A(\mu)$ is the probability that it is $\mu$.”</em> For conversion modeling, we usually pick the <a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta distribution</a> to model the $\mu$ conversion parameter. The Beta distribution has two parameters, $\alpha$ and $\beta$, its peak is at $\frac { \alpha }{ \alpha + \beta }$, its domain is the range $[0, 1]$. Given an experimental outcome where we observed $C$ conversions out of $N$ cases, we set $\alpha=C$ and $\beta=N-C$, so $\alpha$ is the conversion count, $\beta$ is the non-conversion count. The Beta distribution is available in <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html">scipy</a>, it’s easy to visualize:</p>
<div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">convs</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.90</span><span class="p">,</span> <span class="mf">0.97</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">legends</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">conv</span> <span class="ow">in</span> <span class="n">convs</span><span class="p">:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">conv</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">conv</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
    <span class="n">legends</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;Beta(</span><span class="si">%s</span><span class="s1">, </span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">legends</span><span class="p">)</span>
</pre></div>


<p><img src="/images/bayes1.png" alt="Beta distributions" style="width: 600px;"/></p>
<h2>Computing the bayesian probability</h2>
<p>Given the parameter distributions for A and B, we can compute the probability that B’s conversion is greater than A’s: $P(\mu_A \leq \mu_B) = \int_{\mu_A \leq \mu_B} P_A(\mu_A) P_B(\mu_B) = \int_{\mu_A \leq \mu_B} Beta_{\alpha=C_A, \beta=N_A-C_A} (\mu_A) Beta_{\alpha=C_B, \beta=N_B-C_B} (\mu_B) $. To evaluate the integral, we can either use a <a href="https://towardsdatascience.com/bayesian-a-b-testing-with-python-the-easy-guide-d638f89e0b8a">closed form solution from this post</a>, or use Monte Carlo integration (sampling) to estimate. Implementing the MC integration is good practice, and we can use it to make sure the copy/pasted closed form is correct:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">bayesian_prob_mc</span><span class="p">(</span><span class="n">observations</span><span class="p">,</span> <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000</span><span class="o">*</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">beta_A</span> <span class="o">=</span> <span class="n">beta</span><span class="p">(</span><span class="n">observations</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">observations</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">beta_B</span> <span class="o">=</span> <span class="n">beta</span><span class="p">(</span><span class="n">observations</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">observations</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">samples_A</span> <span class="o">=</span> <span class="n">beta_A</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>
    <span class="n">samples_B</span> <span class="o">=</span> <span class="n">beta_B</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>
    <span class="n">hits</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">a</span> <span class="o">&lt;=</span> <span class="n">b</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">samples_A</span><span class="p">,</span> <span class="n">samples_B</span><span class="p">)])</span>
    <span class="k">return</span> <span class="n">hits</span><span class="o">/</span><span class="n">num_samples</span>
</pre></div>


<p>Let’s see it in action, and let’s also show what we would get with a one-tailed z-test:</p>
<div class="highlight"><pre><span></span><span class="n">funnels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[[</span><span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the first vector is the actual outcomes,</span>
    <span class="p">[[</span><span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the second is the traffic split</span>
<span class="p">]</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">observations</span> <span class="o">=</span> <span class="n">simulate_abtest</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Observations:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">observations</span><span class="p">)</span>
<span class="n">pf</span> <span class="o">=</span> <span class="n">z_test</span><span class="p">(</span><span class="n">observations</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;z-test p = </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">pf</span><span class="p">)</span>
<span class="n">pb</span> <span class="o">=</span> <span class="n">bayesian_prob</span><span class="p">(</span><span class="n">observations</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Bayesian p = </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">pb</span><span class="p">)</span>
<span class="n">pb</span> <span class="o">=</span> <span class="n">bayesian_prob_mc</span><span class="p">(</span><span class="n">observations</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Bayesian MC p = </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">pb</span><span class="p">)</span>
</pre></div>


<p>Prints something like:</p>
<div class="highlight"><pre><span></span>Observations:
 [[273 245]
 [242 240]]
z-test p      = 0.215
Bayesian p    = 0.785
Bayesian MC p = 0.785
</pre></div>


<p>The results look good. Note that the z-test p-value $p_f$ and the Bayesian probability $p_b$ add to 1. What’s going on?</p>
<h2>Bayesian Beta modeling vs the frequentist z-test</h2>
<p>Let’s evaluate this by running 100 A/B tests, and plotting both $p_f$ and $p_b$:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_simulations</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">num_simulations</span><span class="p">):</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_simulations</span><span class="p">):</span>
        <span class="n">observations</span> <span class="o">=</span> <span class="n">simulate_abtest</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
        <span class="n">pf</span> <span class="o">=</span> <span class="n">z_test</span><span class="p">(</span><span class="n">observations</span><span class="p">)</span>
        <span class="n">pb</span> <span class="o">=</span> <span class="n">bayesian_prob</span><span class="p">(</span><span class="n">observations</span><span class="p">)</span>
        <span class="n">conv_A</span> <span class="o">=</span> <span class="n">conversion</span><span class="p">(</span><span class="n">observations</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">conv_B</span> <span class="o">=</span> <span class="n">conversion</span><span class="p">(</span><span class="n">observations</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">conv_B</span> <span class="o">-</span> <span class="n">conv_A</span><span class="p">,</span> <span class="n">pf</span><span class="p">,</span> <span class="n">pb</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span> <span class="k">if</span> <span class="n">conv_A</span> <span class="o">&lt;=</span> <span class="n">conv_B</span> <span class="k">else</span> <span class="s1">&#39;red&#39;</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">results</span>

<span class="n">funnels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[[</span><span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the first vector is the actual outcomes,</span>
    <span class="p">[[</span><span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the second is the traffic split</span>
<span class="p">]</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">num_simulations</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">run_simulations</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">num_simulations</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;z-test p&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Bayesian p&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">take</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span><span class="o">=</span><span class="n">take</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="n">take</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img src="/images/bayes2.png" alt="p_f vs p_b" style="width: 400px;"/></p>
<p>It seems that the two add up to 1. But they don’t add up to 1 exactly, it’s just an approximation (using the exact closed-form Bayesian evaluation, not the MC):</p>
<div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">run_simulations</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">num_simulations</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">results</span><span class="p">])</span>
</pre></div>


<p><img src="/images/bayes15.png" alt="p_f vs p_b" style="width: 400px;"/></p>
<p>What’s going on here? One of the things every data scientist knows is that, if given $p_f$, it doesn’t mean that the probability that the action hypothesis is true is $1-p_f$.</p>
<p>Let’s repeat the above experiment, but with different $N$ sample sizes, different conversions, and also look at cases when the action hypothesis is actually true (funnel B is in fact better). Green dots are cases when the outcome of the experiment was such that B’s conversion was better than A (irrespective of the true conversions), red the opposite, for easier readability. In all cases, 100 A/B tests are performed, and the results are plotted.</p>
<p>$N=1000$, A and B are both 50%:</p>
<div class="highlight"><pre><span></span><span class="n">funnels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[[</span><span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the first vector is the actual outcomes,</span>
    <span class="p">[[</span><span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the second is the traffic split</span>
<span class="p">]</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">1000</span>
</pre></div>


<p><img src="/images/bayes4.png" alt="p_f vs p_b" style="width: 600px;"/></p>
<p>$N=1000$, B’s conversion is better than A’s (53% vs 50%):</p>
<div class="highlight"><pre><span></span><span class="n">funnels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[[</span><span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the first vector is the actual outcomes,</span>
    <span class="p">[[</span><span class="mf">0.47</span><span class="p">,</span> <span class="mf">0.53</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the second is the traffic split</span>
<span class="p">]</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">1000</span>
</pre></div>


<p><img src="/images/bayes5.png" alt="p_f vs p_b" style="width: 600px;"/></p>
<p>In this case, we’re sampling the same curves, but in the region where B’s conversion is better than A’s (more green dots in the green section of the curve).</p>
<p>$N=10,000$, A and B are both 1%:</p>
<div class="highlight"><pre><span></span><span class="n">funnels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[[</span><span class="mf">0.99</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the first vector is the actual outcomes,</span>
    <span class="p">[[</span><span class="mf">0.99</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the second is the traffic split</span>
<span class="p">]</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="mi">1000</span>
</pre></div>


<p><img src="/images/bayes6.png" alt="p_f vs p_b" style="width: 600px;"/></p>
<p>The equation $p_f + p_b \simeq 1 $ seems to hold in all these cases!</p>
<h2>Explanation</h2>
<p>With the Z-test, we assume that the Central Limit Theorem (CLT) holds, and model the standard error of the mean (the mean is the conversion) of each funnel with a normal variable $N$, centered on the measured conversion $\mu$, and variance $\sigma^2 = \mu * (1 - \mu) / N$. The difference in conversion is also a normal variable, $N = N_B - N_A$, this has mean $\mu = \mu_B - \mu_A$ and variance $\sigma^2 = \sigma_A^2 + \sigma_B^2$. Then we assume the null hypothesis is true, and calculate the probability of getting at least as extreme results as observed (wrt conversion difference), so we take the integral of the normal from 0 to $\infty$.</p>
<p>With the Bayesian model, we model the actual conversion parameter with a Beta distribution. As long as the $Beta(\alpha, \beta)$ distribution and the $N(\mu, \sigma^2)$ are close enough (with $\mu = \frac{ \alpha }{ \alpha + \beta } $), the two probabilities will be complementary, since in the Bayesian framework we’re computing the complimentary probability. Let’s compare some Beta and normal distributions under with different sample sizes and conversions to check how close these distributions are:</p>
<p><img src="/images/bayes7.png" alt="Beta vs normal distributions" style="width: 600px;"/></p>
<p>Thanks to the CLT, the only time when the Beta pdf and the normal pdf are noticably different is when we’re close to 0 or 1 in conversion probability, and we’re at low sampe sizes $N$ (top right case, above). We can visualize this directly:</p>
<div class="highlight"><pre><span></span><span class="n">funnels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[[</span><span class="mf">0.90</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the first vector is the actual outcomes,</span>
    <span class="p">[[</span><span class="mf">0.90</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the second is the traffic split</span>
<span class="p">]</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
</pre></div>


<p><img src="/images/bayes8.png" alt="p_f vs p_b" style="width: 600px;"/></p>
<p>There is now a noticable spread in the curves, and the “error” in the $p_f + p_b \simeq 1$ line goes as high as 0.04:</p>
<p><img src="/images/bayes16.png" alt="p_f vs p_b" style="width: 400px;"/></p>
<p>In earlier posts I showed that at moderate $N$ the <a href="http://bytepawn.com/ab-testing-and-the-ttest.html">t-test and the z-test quickly become the same thing</a>, so exchanging the z-test for the t-test doesn’t make a difference.</p>
<h2>Bayesian Beta modeling vs the frequentist Fisher’s exact test</h2>
<p>Let's do the same, but instead of using the Z-test, let's use Fisher's exact test (which doesn't have a normal distribution assumption) to get the frequentist $p_f$.</p>
<div class="highlight"><pre><span></span><span class="n">funnels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[[</span><span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the first vector is the actual outcomes,</span>
    <span class="p">[[</span><span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">],</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># the second is the traffic split</span>
<span class="p">]</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>


<p><img src="/images/bayes10.png" alt="p_f vs p_b" style="width: 600px;"/></p>
<p>... and the same at $N=1000$:</p>
<p><img src="/images/bayes11.png" alt="p_f vs p_b" style="width: 600px;"/></p>
<p>At high $N$, $p_f + p_b \simeq 1$ also approximately holds, since here all these frequentist tests become the Z-test.</p>
<p>Question: why the concave relationship at low $N$?</p>
<h2>Bayesian modeling with normals, priors</h2>
<p>There is no set rules for how to perform Bayesian modeling, it is the modeler's choice. It is up to us what kind of distributions we use to model the conversion parameter for our funnels. For example, another popular choice (other than the Beta) is the normal distributions. It goes without saying that if we did that, with the parameters chosen as mentioned above for the z-test, we could get exactly complementary probabilities.</p>
<p>Another choice we have in Bayesian modeling is the prior. The prior is some up-front belief we have about the distribution of the conversions, which we then update based on the outcome of the experiment to get the posterior distribution. Two popular choices are $Beta(1, 1)$, which happens to be the uniform distribution, and $Beta(0.5, 0.5)$, called the Jeffreys prior:</p>
<div class="highlight"><pre><span></span><span class="c1"># common priors</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Beta(1, 1)&#39;</span><span class="p">,</span> <span class="s1">&#39;Beta(0.5, 0.5)&#39;</span><span class="p">])</span>
</pre></div>


<p><img src="/images/bayes12.png" alt="p_f vs p_b" style="width: 400px;"/></p>
<p>When we have a prior belief expressed as a Beta distribution $Beta(\alpha_0, \beta_0)$, after we run the A/B test which yields $\alpha$ conversions and $\beta$ non-conversion events, the posterior will be the Beta distribution $Beta(\alpha_0+\alpha, \beta_0+\beta)$. As you can imagine, at reasonable samples sizes such as $N&gt;100$, Beta priors with relatively low parameters don’t matter much; this is called “washing out the prior with observations”.</p>
<p>However, note that any sort of prior can be chosen, including a very strong one that doesn’t wash out with $N=1000$ samples, like $Beta(1M, 1M)$; this is saying the modeler has a very strong prior belief that the conversion is 50%, and she needs to see millions of observations to convince her otherwise; getting 10 out of 100 will not convince her, since $Beta(1M+10, 1M+100) \simeq Beta(1M, 1M)$ is still a peak around 0.5 (notice the x-axis):</p>
<p><img src="/images/bayes14.png" alt="Strong prior" style="width: 600px;"/></p>
<p>This is a modeling decision. Obviously, with strong priors like this $p_f + p_b \simeq 1$ will not hold (since $p_b$ will be frozen until a lot of observations are collected). Also, any distribution can be chosen by the modeler for the posterior.</p>
<h2>Conclusion</h2>
<p>So in general, the $p_f + p_b \simeq 1$ approximation is not true, it only happens to roughly hold when:</p>
<ul>
<li>using Z-tests on the frequentist side (or other tests whose p value becomes the Z-test's at large $N$), and</li>
<li>using Beta distributions (or other distributions that become roughly normal at large $N$) for Bayesian modeling, and</li>
<li>using a weak prior that is washed out </li>
</ul>
<p>Turning it around: Bayesian inference, when applied to A/B testing using Beta distributions (or other distributions that become normal at large $N$) and weak priors, at reasonable sample sizes, yields roughly complementary probabilities to frequentist tests such as the Z-test (or other tests whose p value becomes the Z-test's at large $N$): $p_f + p_b \simeq 1$. At the end of the day, in conversion A/B testing, in the absence of strong prior beliefs, at reasonable sample sizes we end up putting roughly gaussian shaped functions around measured averages, so different statistical procedures yield roughly the same (complementary) probabilities and decisions.</p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="/tag/bayesian.html">bayesian</a>
      <a href="/tag/ab-test.html">ab-test</a>
    </p>
  </div>
</article>

    <footer>
      <p>&copy; Marton Trencseni </p>
<p>Built using <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a></p>    </footer>
  </main>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1812620-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1812620-2');
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "name": "Bayesian A/B conversion tests",
  "headline": "Bayesian A/B conversion tests",
  "datePublished": "2020-03-31 00:00:00+02:00",
  "dateModified": "2020-03-31 00:00:00+02:00",
  "author": {
    "@type": "Person",
    "name": "Marton Trencseni",
    "url": "/author/marton-trencseni.html"
  },
  "image": "{{ SITEURL }}/{{ THEME_STATIC_DIR }}/img/profile.png",
  "url": "/bayesian-ab-conversion-tests.html",
  "description": "I compare probabilities from Bayesian A/B testing with Beta distributions to frequentist A/B tests using Monte Carlo simulations. Under a lot of circumstances, the bayesian probability of the action hypothesis being true and the frequentist p value are complementary."
}
</script></body>
</html>