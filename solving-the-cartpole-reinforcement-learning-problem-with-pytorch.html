<!DOCTYPE html>
<html lang="en">
<head>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
    styles: {
    ".MathJax .mo, .MathJax .mi": {color: "black ! important"}}
    },
    tex2jax: {
      inlineMath: [['$','$'], ['\\\\(','\\\\)']],
      displayMath: [['$$','$$'], ["\\[","\\]"]],
      processEscapes: true,
    }
    });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" type="text/css" href="/theme/css/style.min.css">
  <!--<link rel="stylesheet" type="text/css" href="/theme/css/pygments.min.css">-->
  <link rel="stylesheet" type="text/css" href="/theme/css/pygments/github.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/font-awesome.min.css">
  <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Bytepawn Atom">

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />
<meta name="author" content="Marton Trencseni" />
<meta name="description" content="The CartPole problem is like the "Hello World" of Reinforcement Learning (RL), originally described in 1985 by Sutton et al. The environment is a pole balanced on a cart. We "derive" a simple a RL solution with Pytorch." />
<meta name="keywords" content="python, pytorch, reinforcement, learning">
<meta property="og:site_name" content="Bytepawn"/>
<meta property="og:title" content="Solving the CartPole Reinforcement Learning problem with Pytorch"/>
<meta property="og:description" content="The CartPole problem is like the "Hello World" of Reinforcement Learning (RL), originally described in 1985 by Sutton et al. The environment is a pole balanced on a cart. We "derive" a simple a RL solution with Pytorch."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="/solving-the-cartpole-reinforcement-learning-problem-with-pytorch.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2019-10-22 00:00:00+02:00"/>
<meta property="article:modified_time" content="2019-10-22 00:00:00+02:00"/>
<meta property="article:author" content="/author/marton-trencseni.html">
<meta property="article:section" content="Machine Learning"/>
<meta property="article:tag" content="python"/>
<meta property="article:tag" content="pytorch"/>
<meta property="article:tag" content="reinforcement"/>
<meta property="article:tag" content="learning"/>
<meta property="og:image" content="/images/cartpole.gif"/>

  <title>Bytepawn &ndash; Solving the CartPole Reinforcement Learning problem with Pytorch</title>
</head>
<body>
  <aside>
    <div>
      <a href="/">
        <img src="/theme/img/profile.png" alt="" title="">
      </a>
      <h1><a href=""></a></h1>
      <p></p>
      <nav>
        <ul class="list">
          <li><a href="/">home</a></li>
          <li><a href="https://github.com/mtrencseni">github</a></li>
          <li><a href="https://www.linkedin.com/in/mtrencseni">linkedin</a></li>
          <li><a href="http://arxiv.org/find/all/1/au:+trencseni/0/1/0/all/0/1">arxiv</a></li>
        </ul>
      </nav>
      <ul class="social">
      </ul>
    </div>
  </aside>
  <main>

<article>
  <header>
    <h1 id="solving-the-cartpole-reinforcement-learning-problem-with-pytorch">Solving the CartPole Reinforcement Learning problem with Pytorch</h1>
    <p>Posted on Tue 22 October 2019 in <a href="/category/machine-learning.html">Machine Learning</a></p>
  </header>
  <div>
    <h2>Introduction</h2>
<p>The CartPole problem is like the <a href="https://en.wikipedia.org/wiki/%22Hello,_World!%22_program">“Hello World”</a> of Reinforcement Learning, originally described in <a href="http://www.incompleteideas.net/papers/OSB-tracking-85.pdf">1985 by Sutton et al</a>. The environment is a pole balanced on a cart. The environment’s state is described by a 4-tuple:</p>
<p><code>(x position of cart, x velocity of cart, angular position of pole, angular velocity of pole)</code></p>
<p>At every timestep, the physics simulation is updated. The input is +1 or -1, depending on whether we want to move the cart to the left or to the right.</p>
<p>With the OpenAI Gym environment, we don’t have to code up the physics simulation, <a href="https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py">it comes out of the box</a>. We just have to:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gym</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;CartPole-v1&#39;</span><span class="p">)</span>
</pre></div>


<p><img src="/images/cartpole.gif" alt="Cartpole animation" style="width: 800px;"/></p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="/tag/python.html">python</a>
      <a href="/tag/pytorch.html">pytorch</a>
      <a href="/tag/reinforcement.html">reinforcement</a>
      <a href="/tag/learning.html">learning</a>
    </p>
  </div>
</article>

    <footer>
      <p>&copy; Marton Trencseni </p>
<p>Built using <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a></p>    </footer>
  </main>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "name": "Solving the CartPole Reinforcement Learning problem with Pytorch",
  "headline": "Solving the CartPole Reinforcement Learning problem with Pytorch",
  "datePublished": "2019-10-22 00:00:00+02:00",
  "dateModified": "2019-10-22 00:00:00+02:00",
  "author": {
    "@type": "Person",
    "name": "Marton Trencseni",
    "url": "/author/marton-trencseni.html"
  },
  "image": "{{ SITEURL }}/{{ THEME_STATIC_DIR }}/img/profile.png",
  "url": "/solving-the-cartpole-reinforcement-learning-problem-with-pytorch.html",
  "description": "The CartPole problem is like the "Hello World" of Reinforcement Learning (RL), originally described in 1985 by Sutton et al. The environment is a pole balanced on a cart. We "derive" a simple a RL solution with Pytorch."
}
</script></body>
</html>