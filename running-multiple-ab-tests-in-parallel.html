<!DOCTYPE html>
<html lang="en">
<head>
  <meta name="google-site-verification" content="14dvQcWyDWHBo8aM0kld8XzEa6KypAzCQDz1_KPus9E" />
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-1812620-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-1812620-2');
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
    styles: {
    ".MathJax .mo, .MathJax .mi": {color: "black ! important"}}
    },
    tex2jax: {
      inlineMath: [['$','$'], ['\\\\(','\\\\)']],
      displayMath: [['$$','$$'], ["\\[","\\]"]],
      processEscapes: true,
    }
    });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" type="text/css" href="/theme/css/style.min.css">
  <!--<link rel="stylesheet" type="text/css" href="/theme/css/pygments.min.css">-->
  <link rel="stylesheet" type="text/css" href="/theme/css/pygments/github.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/font-awesome.min.css">
  <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Bytepawn - Marton Trencseni Atom">

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />
<meta name="author" content="Marton Trencseni" />
<meta name="description" content="It is possible to run multiple A/B tests at once and measure accurate lifts on the same metric by randomizing user assignments into A/B test experiments." />
<meta name="keywords" content="ab-testing">
<meta property="og:site_name" content="Bytepawn - Marton Trencseni"/>
<meta property="og:title" content="Running multiple A/B tests in parallel"/>
<meta property="og:description" content="It is possible to run multiple A/B tests at once and measure accurate lifts on the same metric by randomizing user assignments into A/B test experiments."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="/running-multiple-ab-tests-in-parallel.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2020-04-06 00:00:00+02:00"/>
<meta property="article:modified_time" content="2020-04-06 00:00:00+02:00"/>
<meta property="article:author" content="/author/marton-trencseni.html">
<meta property="article:section" content="Data"/>
<meta property="article:tag" content="ab-testing"/>
<meta property="og:image" content="/images/abpa4.png"/>

  <title>Bytepawn - Marton Trencseni &ndash; Running multiple A/B tests in parallel</title>
</head>
<body>
  <aside>
    <div>
      <a href="/">
        <img src="/theme/img/profile.png" alt="" title="">
      </a>
      <!--<h2><a href="">Bytepawn - Marton Trencseni</a></h2>-->
      <h2><a href="http://bytepawn.com">Bytepawn</a></h2>
      <p></p>
      <nav>
        <ul class="list">
          <li><a href="/">home</a></li>
          <li><a href="https://github.com/mtrencseni">github</a></li>
          <li><a href="https://www.linkedin.com/in/mtrencseni">linkedin</a></li>
          <li><a href="http://arxiv.org/find/all/1/au:+trencseni/0/1/0/all/0/1">arxiv</a></li>
        </ul>
      </nav>
      <ul class="social">
      </ul>
    </div>
  </aside>
  <main>

<article>
  <header>
    <h1 id="running-multiple-ab-tests-in-parallel">Running multiple A/B tests in parallel</h1>
    <p>Marton Trencseni - Mon 06 April 2020 - <a href="/category/data.html">Data</a></p>
  </header>
  <div>
    <h2>Introduction</h2>
<p>Suppose we have N=100,000 users and want to run 2 A/B test experiments, $E_1$ and $E_2$, both of which are trying to move the same metric. In this post I will assume the metric we are trying to move is timespent (or something like it, a number assigned to each user), but the same logic also applies to conversions; timespents yield better illustrations of concepts, as we will see.</p>
<p>It is a common misconception that when running two experiments, we have to split our users between the two experiments, so each experiment will have 50,000 users in it, and each bucket (A in $E_1$, B in $E_1$, A in $E_2$, B in $E_2$) will have 25,000 users. The explanation for this misconception is that if a user is in both experiments, then we wouldn’t be able to tell which experiment led to the user spending more time. This is an error in statistical reasoning, because we don’t really care about why an <em>individual</em> reason spent more or less time with the product; what we care about is measuring the average timespent between A and B. As long as that measurement is accurate, individual users’ being influenced by multiple experiments is irrelevant. Accurate here means that we would measure the same thing (statistically) if we were running only one A/B test.</p>
<p>However, this is a As this post shows, there is no need to limit the sample sizes like this, both experiments can run on all 100,000 users, in parallel.</p>
<p>Note: but, there could be technical reasons that don’t allow parallel experiments, for example if $E_1$ and $E_2$ both make a change to the same UI element in the product.</p>
<h2>Modeling the experiments</h2>
<p>To understand why parallel experiments work, let’s remember how an A/B test is modeled in our simulations: each user is represented by a independent random variable (RV). Independent, because we assume users don’t affect each other (so, we’re not in a social network setting here), and it’s a random variable because individual user outcomes are random. In this post, like before, I will use an exponential random variable to model timespents. The exponential distribution has one parameter, $\mu$, which works out to be the mean. I will assume that by default, users have $\mu=1$.</p>
<p>In our timespent simulations, when we day that an A/B test is actually working, we model this by increasing the$\mu$ parameter for the user’s random variable. In the end, we will sample the random variable, so the actual outcome can be any timespent $t&gt;0$, but on average, users with lifted parameters will have higher timespents. This is the key: in an A/B test, we don’t care about individual user’s outcomes, since they are statistically random anyway, we care about measuring accurate average lifts between groups of users.</p>
<h2>Visualizing one A/B test</h2>
<p>There is an easy visual way to understand why parallel A/B tests work. Before we look at the parallel cases, as a starting point, let’s look at the simple case of just one experiment. We can use code like in the previous posts for this:</p>
<div class="highlight"><pre><span></span><span class="n">N</span><span class="o">=</span><span class="mi">10</span><span class="o">*</span><span class="mi">1000</span>
<span class="n">funnels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">1.00</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
<span class="p">]</span>
<span class="n">timespent_params</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="n">timespents</span> <span class="o">=</span> <span class="p">{}</span>

<span class="n">funnel_assignment</span> <span class="o">=</span> <span class="n">simulate_abtest</span><span class="p">(</span><span class="n">funnels</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">timespent_params</span><span class="p">,</span> <span class="n">force_equal</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">timespent_params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">timespents</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">expon</span><span class="p">(</span><span class="n">param</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>


<p>What this code is doing: there are $N=10,000$ users, we will split them evenly between A and B funnels in the experiment <code>funnels</code>, 2nd column. Each user is modeled by an exponential random variable <code>timespent_params</code>, which has default parameter 1. The function <code>simulate_abtest</code> assigns each user into A or B, it returns this assignment into <code>funnel_assignment</code>. Further, it adjusts the <code>timespent_params</code>, by increasing the RV’s parameter for users in the B bucket by 1, leaving As alone (<code>funnels</code> 1st column). The final <code>for</code> loop samples the exponential distributions and stores the actual timespents.</p>
<p>We can visualize the outcome of this experiment by drawing both the parameters and the actual timespents of each user. Since there are $N=10,000$ users, we can do so on a 100x100 image. The left side shows the parameters ($\mu=1$ or $\mu=2$), the right side shows the actual, sampled timespents.</p>
<p><img src="/images/abpa1.png" alt="" style="width: 400px;"/></p>
<p>Let’s change our visualization a little bit: let’s make it so we draw the A bucket users on top, and the B bucket users on the bottom:</p>
<p><img src="/images/abpa2.png" alt="" style="width: 400px;"/></p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="/tag/ab-testing.html">ab-testing</a>
    </p>
  </div>
</article>

    <footer>
      <p>&copy; Marton Trencseni </p>
<p>Built using <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a></p>    </footer>
  </main>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1812620-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1812620-2');
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "name": "Running multiple A/B tests in parallel",
  "headline": "Running multiple A/B tests in parallel",
  "datePublished": "2020-04-06 00:00:00+02:00",
  "dateModified": "2020-04-06 00:00:00+02:00",
  "author": {
    "@type": "Person",
    "name": "Marton Trencseni",
    "url": "/author/marton-trencseni.html"
  },
  "image": "{{ SITEURL }}/{{ THEME_STATIC_DIR }}/img/profile.png",
  "url": "/running-multiple-ab-tests-in-parallel.html",
  "description": "It is possible to run multiple A/B tests at once and measure accurate lifts on the same metric by randomizing user assignments into A/B test experiments."
}
</script></body>
</html>